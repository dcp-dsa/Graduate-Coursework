{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Data parsing modules and packages\n",
    "\n",
    "Data parsing and manipulation is a cornerstone of Python functionality for the Data Scientist.  For every file format, there is typically one or more Python libraries which are suitable for parsing the file into memory data structures.\n",
    "\n",
    "We will look at a few examples and you will continue this practical exploration for the the end of day learning exercises.\n",
    "\n",
    " \n",
    "## Pandas ... again  ![Panda Sleeping](../images/panda-sleep-2.jpg)\n",
    "\n",
    "Pandas library is very useful. Please read through \n",
    "https://pandas.pydata.org/pandas-docs/stable/overview.html#data-structures\n",
    "\n",
    "As you have seen before, we will import some libraries. Specifically, NUMPY and PANDAS and this time we are aliasing them as np and pd, respectively.\n",
    "\n",
    "**Example: loading a file and examining the column headers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Here we create a dataframe\n",
    "df = pd.read_csv('/dsa/data/all_datasets/SyriaIDPSites2015LateJunHIUDoS.csv', encoding='latin-1')\n",
    "# Show the Column Headings\n",
    "print(df.columns)\n",
    "```\n",
    "\n",
    "```\n",
    "Index(['Description', 'Country', 'ADM1', 'ADM2', 'ADM3', 'ADM4', 'Latitude',\n",
    "       'Longitude', 'Name', 'pcode', 'fips', 'iso_alpha2', 'iso_alpha3',\n",
    "       'iso_num', 'stanag', 'tld'],\n",
    "      dtype='object')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JavaScript Object Notation (JSON)\n",
    "\n",
    "The library that we previously saw, json, is capable of both reading and writing JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import json\n",
    "\n",
    "file_data = json.load(open('/dsa/data/all_datasets/Syria_IDPSites_2015LateJun_HIU_DoS.geojson', encoding='latin-1'))\n",
    "print(str(file_data)[1:300], \" ...\")\n",
    "```\n",
    "\n",
    "```\n",
    "'crs': {'properties': {'name': 'urn:ogc:def:crs:EPSG::4326'}, 'type': 'name'}, 'totalFeatures': 52, 'type': 'FeatureCollection', 'features': [{'geometry': {'coordinates': [36.447, 32.588], 'type': 'Point'}, 'properties': {'iso_alpha2': 'SY', 'stanag': 'SYR', 'iso_alpha3': 'SYR', 'tld': '.sy', 'Name  ...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://docs.python.org/3/library/json.html for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comma Separated Values (CSV)\n",
    "\n",
    "Example loading a CSV file, then writing a JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import csv\n",
    "import json\n",
    "# Open an output file, in (w)rite mode\n",
    "jsonfile = open('MyOutput.json', 'w')\n",
    "# Read File Data, using the dictionary reader\n",
    "# Define the field names.  Look into CSV library deeper for details\n",
    "fieldnames = ('Description', 'Country', 'ADM1', 'ADM2', 'ADM3', 'ADM4', 'Latitude', 'Longitude', 'Name', 'pcode', 'fips', 'iso_alpha2', 'iso_alpha3', 'iso_num', 'stanag', 'tld')\n",
    "file_data = csv.DictReader(open('SyriaIDPSites2015LateJunHIUDoS.csv', encoding='latin-1'), fieldnames)\n",
    "# Now transform\n",
    "for data_row in file_data:\n",
    "    json.dump(data_row, jsonfile)\n",
    "    jsonfile.write('\\n')\n",
    "jsonfile.close();\n",
    "```\n",
    " \n",
    "\n",
    "See https://docs.python.org/3/library/csv.html  for additional information.\n",
    "\n",
    "\n",
    "\n",
    "## BeautifulSoup\n",
    "\n",
    "Beautiful Soup is a great HTML/XML parser. \n",
    "\n",
    "This example parses a KML file, which is a version of XML.  HTML and XML are hierarchical data files, but still text-based files.\n",
    "\n",
    "```\n",
    "# Beautiful Soup\n",
    "from bs4 import BeautifulSoup\n",
    " \n",
    "# Open the file as a file object\n",
    "# Parse the file object into a XML Structured Document, AKA : KML Document Object Model (DOM)\n",
    "with open('geonode-Syria_IDPSites_2015LateJun_HIU_DoS.kml') as kml_file_object:\n",
    "    dom = BeautifulSoup(kml_file_object,'xml')\n",
    "    \n",
    "for pm in dom.findAll('Placemark'):\n",
    "    for name in pm.findAll('name'):\n",
    "        nametext = name.find(text = True)\n",
    "        print(nametext)\n",
    "```\n",
    "\n",
    "Please review this link for much information on beautiful soup! http://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    " \n",
    "\n",
    " \n",
    "## General Advanced Parsing\n",
    "\n",
    "In general, given a file format that is commonly known, someone else has already written Python code to handle it.  Search the internet for python and the name of the file type together.\n",
    "\n",
    "Once you have parsed the data into memory, you simply need to iterate through it (recall Think Python, Chapter 7).\n",
    "\n",
    "The data may be in pandas or moved to pandas, the choice is often yours and just a couple lines of code away.  When you work through the Database and SQL course, you will see this concept applied for MS Excel Spreadsheet files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
