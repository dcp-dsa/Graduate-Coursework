{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Practice with Beautiful Soup and ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Construct a series of cells that will pull this URL and ingest it into SQLite3 database\n",
    "\n",
    "https://factfinder.census.gov/bkmk/table/1.0/en/GEP/2014/00A4/0100000US\n",
    "\n",
    "Because the table is loaded via scripts, you'll want to use the following for parsing:\n",
    "https://indigo.sgn.missouri.edu/static/mirror_sites/factfinder.census.gov/bkmk/table/1.0/en/GEP/2014/00A4/0100000US\n",
    "\n",
    "\n",
    "![Census Data](../images/census_data_look.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Data table element\n",
    "```\n",
    "<table id=\"data\" class=\"stat-tbl\">\n",
    "```\n",
    "\n",
    "**Please organize your code in the cells below.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import os\n",
    "import sqlite3\n",
    "import numpy\n",
    "# Pull the HTML link into a local file or buffer\n",
    "#   and then parse with the BeautifulSoup library\n",
    "# ------------------------------------------------\n",
    "\n",
    "# Grab the website data\n",
    "# Open the URL in your browser and follow along with the page inspector (Ctrl+Shift+I)\n",
    "url = 'https://indigo.sgn.missouri.edu/static/mirror_sites/factfinder.census.gov/bkmk/table/1.0/en/GEP/2014/00A4/0100000US.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "print('Status: ' + str(r.status_code))\n",
    "\n",
    "soup = BeautifulSoup(r.content, \"html\")\n",
    "\n",
    "# Scrape out the table\n",
    "table = soup.find(id='data')\n",
    "\n",
    "#print(table.prettify())\n",
    "\n",
    "# Scrape header for names\n",
    "header_row = table.thead.findAll('th')\n",
    "#print(header_row)\n",
    "\n",
    "# Parse the header names\n",
    "\n",
    "# First one doesn't have a link with a code name. Rude\n",
    "readable_names = ['Geographic Area Name']\n",
    "db_names = ['areaname']\n",
    "\n",
    "for column in header_row[1:]:\n",
    "  readable_names.append(column.text)\n",
    "  messy_name = column.a.attrs['data-vo-id']\n",
    "  messy_name = messy_name[messy_name.rfind('~') + 1:]\n",
    "  messy_name = messy_name[messy_name.rfind('.') + 1:].lower()\n",
    "  db_names.append(messy_name)\n",
    "\n",
    "name_mapping = dict(zip(db_names, readable_names))\n",
    "pprint(name_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into a list of dictionaries\n",
    "#   or some other structure you can convert into\n",
    "#   pandas Data Frame\n",
    "# ------------------------------------------------\n",
    "scraped_data = []\n",
    "\n",
    "# Quick and dirty conversion of types\n",
    "convert = [str,int,str,int,float,int,float,int,float,int,float,int,float,int,float,int,float,int,float]\n",
    "\n",
    "for row in table.tbody.findAll('tr'):\n",
    "  row_data = [x.text for x in row.children]\n",
    "  for idx in range(0,len(convert)):\n",
    "      row_data[idx] = convert[idx](row_data[idx].replace(',','')) # ugh commas break int conversion\n",
    "      # This would kill ANY commas in the data, though. Thankfully there are none.\n",
    "      # If there were, just gate on the conversion function being int\n",
    "  scraped_data.append(dict(zip(db_names, row_data)))\n",
    "\n",
    "pprint(scraped_data[0])\n",
    "\n",
    "frame = pd.DataFrame(scraped_data)\n",
    "\n",
    "print(frame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data into two formats: csv and json\n",
    "# ------------------------------------------------\n",
    "\n",
    "\n",
    "frame.to_csv(\"census.csv\", index=False)  # index=False will make sure the row indices (i.e 0, 1, ...) will not \n",
    "# written to csv file\n",
    "\n",
    "frame.to_json(\"census.json\")\n",
    "\n",
    "\n",
    "# check whether write was done correctly (optional)\n",
    "\n",
    "df_csv = pd.read_csv(\"census.csv\", header=0)\n",
    "print(df_csv.head())\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df_json = pd.read_json(\"census.json\")\n",
    "print(df_json.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
