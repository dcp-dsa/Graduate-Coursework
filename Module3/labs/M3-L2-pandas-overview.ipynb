{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Overview\n",
    "\n",
    "\n",
    "One of the fundamental concepts across Python, R, and databases is the **tabular data structure**, especially with named columns and records as rows. This tabular data structure is usually heterogeneous in nature. \n",
    "In Python, we use the **DataFrame** data structure within the **Pandas** library.\n",
    "In R you will learn of the **native data frame** type.\n",
    "In SQL, the `table` is the fundamental data storage concept.\n",
    "\n",
    "In each of these cases, you have facilities to do operations on a column or row of data. Additionally, you can subset the data by selecting a list of columns and filtering out to only have have particular rows based on boolean (T/F) tests of conditions.\n",
    "Even more complex concepts are possible, as you will see, such as grouping rows for analytics and other operations.\n",
    "\n",
    "<mark>In this lab and in the subsequent labs and practices, you may see repeated information. Sometimes it is necessary so that you become accustomed/familiar to the most frequently used methods/topics.</mark>\n",
    "\n",
    "\n",
    "In this session, examples covered are:\n",
    "\n",
    "1. Delete columns\n",
    "1. Convert column into binary\n",
    "1. Convert column into np.datetime\n",
    "1. Find unique values in a column\n",
    "1. Iterating through columns and excluding columns from iteration\n",
    "1. Drop rows from data frame\n",
    "1. Subset dataframe by columns\n",
    "1. Subset dataframe by rows\n",
    "1. Resample dataset\n",
    "\n",
    "\n",
    "We will walk them through with minimum examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def load_data(filepath='processing_examples.csv'):\n",
    "    dataset = pd.read_csv('processing_examples.csv')\n",
    "    return dataset\n",
    "\n",
    "def raw_state(dataset):\n",
    "    print('====== before ======')\n",
    "    print(dataset)\n",
    "\n",
    "def curr_state(dataset):\n",
    "    print('====== after ======')\n",
    "    print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using a toy dataset (processing_examples.csv) to go over various features of pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "dataset = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show dimension/shape and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape = {dataset.shape}\")\n",
    "print(f\"Num rows = {dataset.shape[0]}\")\n",
    "print(f\"Num rows = {dataset.shape[1]}\")\n",
    "print(f\"Num elements = {dataset.size}\")\n",
    "print(f\"Column names = {dataset.columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the first and last few lines in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())  # default 5 lines\n",
    "print(dataset.tail())  # default 5 lines\n",
    "\n",
    "print(dataset.head(2))  # show first 2 lines\n",
    "print(dataset.tail(2))  # show last 2 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()  # gives some basic stats on the numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update all the values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows an example of zeroing out all elements in a dataset, just so to make sure you could understand the syntax we are using in this lab  and quickly show what jobs these above functions do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "dataset.iloc[:, :] = 0\n",
    "curr_state(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "ret = dataset.drop('float', axis = 1)\n",
    "print('====== returns ======')\n",
    "print(ret)\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "ret = dataset.drop('float', inplace = True, axis = 1)\n",
    "print('====== returns ======')\n",
    "print(ret)\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recommended way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "del dataset['float']\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert column into binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['yes/no'] = dataset['yes/no'].apply(['Yes', 'No'].index)\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['yes/no'] = list(map(['Yes', 'No'].index, dataset['yes/no']))\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert column into np.datatime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['date'] = dataset['date'].apply(np.datetime64)\n",
    "\n",
    "curr_state(dataset)\n",
    "    \n",
    "print(type(dataset['date'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['date'] = dataset['date'].apply(np.datetime64)\n",
    "print('====== day ======')\n",
    "print(dataset['date'].apply(lambda d: d.day))\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['date'] = dataset['date'].apply(np.datetime64)\n",
    "print('====== day ======')\n",
    "print(dataset['date'].apply(lambda d: d.month))\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find unique values in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "print(np.unique(dataset['categorical']))\n",
    "# or \n",
    "print(dataset['categorical'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "for column_name in ['int', 'categorical']:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "for column_name in dataset.columns:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "for column_name in np.array(dataset.columns)[[2,4]]:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "for column_name in np.array(dataset.columns)[[False, True, False, False, True]]:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating through columns with exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "exclusion = ['float', 'yes/no', 'date']\n",
    "\n",
    "for column_name in set(dataset.columns)-set(exclusion):\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "exclusion = [0,2,3]\n",
    "\n",
    "for column_name in set(dataset.columns)-set(np.array(dataset.columns)[exclusion]):\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "exclusion = [0,2,3]\n",
    "\n",
    "for column_name in [v for i,v in enumerate(dataset.columns) if i not in exclusion]:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "exclusion = [True, False, True, True, False]\n",
    "\n",
    "for column_name in np.array(dataset.columns)[~np.array(exclusion)]:\n",
    "    print(dataset[column_name].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop rows from data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset.drop([3,4,5], inplace=True)\n",
    "\n",
    "curr_state(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset.drop([3,4,5], inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset data frame by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "dataset.iloc[:, [1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "dataset.loc[:, ['int', 'yes/no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset.loc[:, filter(lambda i: 'a' in i, dataset.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset.loc[:, filter(lambda i: i.startswith('c') or i.startswith('d'), dataset.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset.loc[:, [i for i in dataset.columns if i.startswith('c') or i.startswith('d')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset data frame by rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset.iloc[[3,4,5], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "print(dataset['int']>5)\n",
    "\n",
    "dataset[dataset['int']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset[(dataset['float']>0.5) & (dataset['yes/no']=='Yes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sidebar: replacing dataset[] with np.sum(), you can get the count of records  \n",
    "satisfying the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "np.sum((dataset['float']>0.5) & (dataset['yes/no']=='Yes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice the usage of dataset[]\n",
    "\n",
    "It acts on either rows or columns depending on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "obj = 'categorical'\n",
    "dataset[obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "obj = [False,False,False,False,True,False,True,False]\n",
    "dataset[obj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was how the following statement could work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "\n",
    "dataset[dataset['categorical']=='C']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And this indexer is also writable on both axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset['categorical'] = ['A']*8\n",
    "\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset[dataset['categorical']=='C'] = [-1, -128, 'No', '0000-00-00', '<<<']\n",
    "\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset[dataset['categorical']=='C'] = [\n",
    "    [-1, -128, 'No', '0000-00-00', '<<<'],\n",
    "    [0, 127, 'Yes', '1900-12-01', '<<<']\n",
    "]\n",
    "\n",
    "curr_state(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset = dataset.sample(frac = 0.2)\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset = dataset.sample(frac = 0.9, replace = True)\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset = dataset.sample(frac = 1)\n",
    "\n",
    "curr_state(dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset = dataset.sample(frac = 1.5, replace = True)\n",
    "\n",
    "curr_state(dataset)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data()\n",
    "raw_state(dataset)\n",
    "\n",
    "dataset = dataset.sample(frac = 1.5, replace = True).reset_index(drop=True)\n",
    "\n",
    "curr_state(dataset)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All done!  Clear Cells, Save Notebook, `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
