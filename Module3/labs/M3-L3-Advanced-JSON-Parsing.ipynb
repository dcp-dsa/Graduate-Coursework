{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Parsing\n",
    "\n",
    "JavaScript Object Notation (JSON) is a increasingly popular data interchange format. There are a variety of specialty derivatives of JSON, such as GeoJSON.\n",
    "\n",
    "JSON objects are constructed of key => value pairs, textual encoding example :  ` { \"key1\" : \"value1\", \"key2\" : \"value2\" } `\n",
    "\n",
    "Values can also be lists of objects in the form of arrays, where the `{...}` represents an object in the array : \n",
    "`[ {...}, {...} ] `\n",
    "\n",
    "In fact, this notebook is encoded as a JSON file.  If you open it in a regular text editor, you can see the structure of it.\n",
    "\n",
    "As an example of how to parse JSON, we'll use the Syrian IDP JSON file.  Note that we use the `json` module for this rather than `BeautifulSoup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_data = json.load(open('/dsa/data/all_datasets/Syria_IDPSites_2015LateJun_HIU_DoS.geojson', encoding='latin-1'))\n",
    "json.dumps(file_data, sort_keys=True, indent=4, separators=(',', ': '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the data looks JSON-ish above.\n",
    "\n",
    "How does it look as a python object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_data = json.load(open('/dsa/data/all_datasets/Syria_IDPSites_2015LateJun_HIU_DoS.geojson', encoding='latin-1'))\n",
    "print(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the same.  Something to remember is the equivalent names between JSON and Python\n",
    "\n",
    "JSON Object = Python (Dict) Dictionary, i.e., name - value pairs\n",
    "   * Read more about Dict here : https://docs.python.org/3.3/library/stdtypes.html#dict\n",
    " \n",
    "JSON Array = Python list\n",
    "   * Read more about List here : https://docs.python.org/3.3/library/stdtypes.html#lists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common operation is to produce JSON formatted files from other data, such as CSV files.  This can be done with the `csv` and `json` modules, but it is simpler to read and write the data using `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the file using pandas\n",
    "import pandas as pd\n",
    "filepath = '/dsa/data/all_datasets/SyriaIDPSites2015LateJunHIUDoS.csv'\n",
    "df = pd.read_csv(filepath, encoding='latin-1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the file using pandas\n",
    "jsonfile = 'MyOutput.json'\n",
    "df.to_json(jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confirm that the JSON file results in the same dataframe\n",
    "df_json = pd.read_json(jsonfile)\n",
    "print(df.shape)\n",
    "print(df_json.shape)\n",
    "print(df_json)       # Columns and rows are in a different order, but looks the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides file I/O, JSON is commonly used as a configuration file format and a data transmission format (e.g., JSON-RPC or pushing/pulling data between a Python program and a web service.\n",
    "\n",
    "Here, we use the `json` module to read a geoJSON file because `pandas` can't read those files.  However, there is now a `GeoPandas` module that *can* [read geoJson](http://geopandas.org/io.html).  This may be a worthwhile alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "file_data = json.load(open('/dsa/data/all_datasets/Syria_IDPSites_2015LateJun_HIU_DoS.geojson', encoding='latin-1'))\n",
    "df = pandas.DataFrame(file_data['features'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten your pandas\n",
    "Looking at the output above, we can see that some columns in the DataFrame (e.g. geometry and properties) are actually embedded dictionaries. This is a common occurrence when dealing with hierarchical data. You will encounter this in many data scraping / parsing scenarios.\n",
    "\n",
    "#### Dig into your data\n",
    "The key is to interrogate your data and iterate your code until you have flattened the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a single entry of the geometry column\n",
    "df.geometry.iloc[0]\n",
    "\n",
    "# Show a single entry of the properties column\n",
    "df.properties.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it\n",
    "Look at the API for Pandas (http://pandas.pydata.org/pandas-docs/stable/api.html) and the code above and try to create a new data frame that completely flattens the record for each feature.\n",
    "\n",
    "The efficient way to do this is to build a list of flattened rows, then instantiate the DataFrame from the list of rows. The alternative is the continual construction of DataFrames from two DataFrames.\n",
    "\n",
    "So, we want to create an empty list, then for each flattened row we will append it as a dictionary into the list.\n",
    "\n",
    "See : https://docs.python.org/3/tutorial/datastructures.html \n",
    "  * Note the list.append(X) function.  \n",
    "\n",
    "See : https://docs.python.org/2/library/stdtypes.html#dict.update \n",
    "  * Note the dictionary merge \"update(X) function\n",
    "\n",
    "\n",
    "**First run this code block.**  It has a `break` statement in it to only run the first iteration, and it is annotated with several print statements to show what is happening.  This code only flattens 'properties'.  It is left to you to do the same with 'geometry'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_rows = []\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Some columns are actually dictionaries for column values\n",
    "    print('Here\\'s what one row looks like:\\n{}\\n'.format(row))\n",
    "    print('Type of \"row\": {}\\n'.format(type(row)))\n",
    "   \n",
    "    rowDict = row.to_dict()   # convert the row object, which is a pandas Series, into a dictionary\n",
    "    \n",
    "    print('rowDict: \\n{}\\n'.format(rowDict))\n",
    "    print('Type of \"rowDict\": {}\\n'.format(type(rowDict)))\n",
    "    \n",
    "    # Note that the properties and geometry keys refer to dictionaries themselves.\n",
    "    # Pull out properties and geometry, and append them to the row  using the \"update\" method.\n",
    "    \n",
    "    properties = rowDict.pop('properties')   # remove the properties field into a variable named properties\n",
    "    \n",
    "    rowDict.update(properties)     # merge in the flattened properties\n",
    "    \n",
    "    print('rowDict: \\n{}\\n'.format(rowDict))\n",
    "    \n",
    "    break  # Stop here before looping to the next row\n",
    "    \n",
    "    # Append the newly flattened row to the list of rows\n",
    "    list_of_rows.append(rowDict)\n",
    "          \n",
    "df2 = pandas.DataFrame(list_of_rows)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"background:yellow;\">Your Turn</span>\n",
    "\n",
    "Now that you have seen the possibilities with the example above, completely flatten the JSON into a panda data frame by flattening the 'geometry' field as well as 'properties', then compute the average longitude and latitude using the coordinates array within the geometry column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "file_data = json.load(open('/dsa/data/all_datasets/Syria_IDPSites_2015LateJun_HIU_DoS.geojson', encoding='latin-1'))\n",
    "df = pandas.DataFrame(file_data['features'])\n",
    "\n",
    "list_of_rows = []\n",
    "for index, row in df.iterrows():\n",
    "    # Do Flattening\n",
    "    # Replace pass with code\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "df2 = pandas.DataFrame(list_of_rows)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE YOUR NOTEBOOK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
