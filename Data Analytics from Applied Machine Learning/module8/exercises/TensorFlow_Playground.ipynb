{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 : Tensor Flow Playground Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, you will focus on interpretation and understanding of neural network behavior in the context of:\n",
    " 1. Input (Data)\n",
    " 1. Architecture\n",
    " 1. Activation Functions\n",
    " 1. Resulting Decision Planes\n",
    " 1. Hyper-parameter Tuning\n",
    "\n",
    "The link below should open the TensorFlow NN Playground to the simple data set.\n",
    "\n",
    "![TFPG_DS_2_blobs.png MISSING](../images/TFPG_DS_2_blobs.png)\n",
    "\n",
    "[Access the TensorFlow Playground](https://playground.tensorflow.org/#activation=linear&batchSize=10&dataset=gauss&regDataset=reg-plane&learningRate=0.00001&regularizationRate=0&noise=0&networkShape=1,1&seed=0.44359&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "#### Dataset\n",
    "\n",
    "![data](../images/Gaussian-Data.png)\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    " * Learnign Rate : <span style=\"background:yellow\">0.003</span> \n",
    " * Activation : <span style=\"background:yellow\">Linear</span>  \n",
    " * Regularization : <span style=\"background:yellow\">None</span>  \n",
    " * Regularization Rate : <span style=\"background:yellow\">0</span>  \n",
    " \n",
    " \n",
    "**Your hyperparameter bar should like below**\n",
    "![TFPG_HyperParameter_Bar.png MISSING](../images/TFPG_HyperParameter_Bar.png) \n",
    "\n",
    "\n",
    "#### Architecture:\n",
    " Start with a 2 hidden layers, one neuron each, only taking as input $X_1$ and $X_2$.\n",
    "\n",
    "![TFPG_E1_Architecture.png MISSING](../images/TFPG_E1_Architecture.png) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task E1\n",
    "  When you are ready, click the play button and watch the model's **training loss**.\n",
    "  When the loss reaches 0.0, pause the training (clicking the button again).\n",
    "  \n",
    "  The result should look similar to:\n",
    "  \n",
    "  ![TFPG_E1_sample_output.png MISSING](../images/TFPG_E1_sample_output.png)\n",
    "  \n",
    "  **Q**: How many epochs did you need to get the training loss down to 0.0?\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E1: Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "512\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture a screen shot of your trained model and embed it \n",
    "**In this Cell, Double Click**, then Adjust the file name at the bottom image markdown after you upload it to the `module8/exercises` folder\n",
    " * For example, you may need to adjust the file extension.\n",
    " \n",
    "```\n",
    "![M8_E1_image.png MISSING](./M8_E1_image.png) --> (./M8_E1_image.jpeg)\n",
    "```\n",
    "\n",
    "![M8_E1.png MISSING](./M8_E1.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Question 2\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    " * Learnign Rate : <span style=\"background:yellow\">0.003</span> \n",
    " * **Activation** : <span style=\"background:yellow\">Sigmoid</span>  \n",
    " * Regularization : <span style=\"background:yellow\">None</span>  \n",
    " * Regularization Rate : <span style=\"background:yellow\">0</span>  \n",
    " \n",
    "\n",
    "#### Architecture:\n",
    " * Input : Only $X_1$ and $X_2$\n",
    " * 1 first hidden layer neuron \n",
    " * 1 second hidden layer neuron \n",
    "\n",
    "\n",
    "#### Task E2:\n",
    "  When you are ready, click the play button and watch the model's **training loss**.\n",
    "  When the loss reaches 0.0, pause the training (clicking the button again).\n",
    "  \n",
    "  **Q**: What is a difference you observe just by changing the activation function?\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E2 Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "it takes over 11,000 more epochs for the network to reach a training loss of 0.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Question 3\n",
    "\n",
    "## Change to Four-Quadrant Data Set\n",
    "\n",
    "![TFPG_4_Quad_DS.png MISSING](../images/TFPG_4_Quad_DS.png)\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    " * Learnign Rate : <span style=\"background:yellow\">0.003</span> \n",
    " * **Activation** : <span style=\"background:yellow\">Linear</span>  \n",
    " * Regularization : <span style=\"background:yellow\">None</span>  \n",
    " * Regularization Rate : <span style=\"background:yellow\">0</span>  \n",
    " \n",
    "\n",
    "#### Architecture:\n",
    " * Input : Only $X_1$ and $X_2$\n",
    " * 1 first hidden layer neuron \n",
    " * 1 second hidden layer neuron \n",
    "\n",
    "#### Task E3:\n",
    "  When you are ready, click the play button and watch the model's **training loss**.\n",
    "  Let training run for 3,000 epochs.\n",
    "    \n",
    "  **Q**: Based on your readings and the videos, why did the NN not converge to near zero loss?\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E3 Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "As I understand, this NN will not converge to zero because we chose to use a linear classifier on an exclusive or dataset (which outputs '1' if the inputs are equal, and '0' if the outputs are opposite). The issue arises because, when plotted, the outputted values are not linearly separable. They will be divided into four quadrants that cannot be separated by a single line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Question 4\n",
    "\n",
    "You will now adjust the activation type and the number of hidden layers to build a good classifier.\n",
    "Please keep track of what you try and log the efforts (Activation Fuction, Neuron Architecture, Final Loss, Epochs of training).\n",
    "\n",
    "**Constraint:** Try to keep the learning rate at 0.003 and only use the inputs $X_1$ and $X_2$.\n",
    "\n",
    "**Goal:** Get the training loss below 0.01; if you can down to 0.001.\n",
    "\n",
    "**Capture:** A screen shot of your final trained model.\n",
    "\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    " * Learnign Rate : <span style=\"background:yellow\">0.003</span> \n",
    " * **Activation** : <span style=\"background:yellow\"> Experiment</span>  \n",
    " * Regularization : <span style=\"background:yellow\">None</span>  \n",
    " * Regularization Rate : <span style=\"background:yellow\">0</span>  \n",
    " \n",
    "\n",
    "#### Architecture:\n",
    " * Input : Only $X_1$ and $X_2$\n",
    " * <span style=\"background:yellow\"> Experiment with </span> hidden layers \n",
    "\n",
    "\n",
    "#### Task E4:\n",
    "\n",
    "**For each architecture you evaluated**\n",
    " * **Q**: Describe your final architecture\n",
    " * **Q**: Detail your hyperparameters\n",
    " * **Q**: How many epochs, and what was your final loss\n",
    "  \n",
    "**Final Q**: What are you take-aways you have from this exercise in regards to architecture versus decision surfaces? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E4 Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "Architecture 1:\n",
    "Hidden layers: 2 (3-2)\n",
    "Activation: sigmoid\n",
    "Epochs: 3,021\n",
    "Final training loss: 0.495\n",
    "\n",
    "Architecture 2:\n",
    "Hidden layers: 2 (3-2)\n",
    "Activation: ReLU\n",
    "Epochs: 5,461\n",
    "Final training loss: 0.348\n",
    "\n",
    "Architecture 3:\n",
    "Hidden layers: 2 (3-2)\n",
    "Activation: Tanh\n",
    "Epochs: 3,113\n",
    "Final training loss: 0.390\n",
    "\n",
    "Architecture 4:\n",
    "Hidden layers: 1 (3)\n",
    "Activation: sigmoid\n",
    "Epochs: 6,074\n",
    "Final training loss: 0.354\n",
    "\n",
    "Architecture 5\n",
    "Hidden layers: 1 (3)\n",
    "Activation: ReLU\n",
    "Epochs: 3,801\n",
    "Final training loss: 0.228\n",
    "\n",
    "Architecture 6\n",
    "Hidden layers: 4 (3-2-2-2)\n",
    "Activation: Tanh\n",
    "Epochs: 1,790\n",
    "Final training loss: 0.001\n",
    "\n",
    "As it turned out, when I only changed the activation function, the resulting training losses did not differ too much. It was only when I started changing the number of hidden layers that I started to see a larger difference. Although first I began reducing the number of hidden layers back to 1, I decided to try one where I increased the number of hidden layers to 4 which turned out to be a very good fit. Another thing that I noticed is that it is not only the parameters I chose that would make a difference, but also what the neurons actually looked like. For example, I could use the exact same input parameters as Architecture 6, and it may not converge the second time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture a screen shot of your final trained model and embed it \n",
    "\n",
    "\n",
    "![E4_image.png MISSING <change here>](./M8_E4.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# Question 5\n",
    "\n",
    "Using the Architecture you found as best above, change data sets to the enclosing configuration.\n",
    "\n",
    "![TFPG_Enclosed_DS.png MISSING](../images/TFPG_Enclosed_DS.png)\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    "**<span style=\"background:yellow\">Experiment</span>**\n",
    " \n",
    "\n",
    "#### Architecture:\n",
    "**<span style=\"background:yellow\">Locked to Final Architecture of Exercise Question 4.</span>**\n",
    "\n",
    "\n",
    "#### Task E5\n",
    "  \n",
    "  **Q**: Provide a detailed assessment of what you observed and any changes you made to the hyper parameters.\n",
    " Pay special attention to discussion of the results decision surfaces, error, and epohcs.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E5 Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "hyperparameters 1:\n",
    "Learning rate: 0.003\n",
    "Activation: Tanh\n",
    "Regularization: None\n",
    "Regularization Rate: 0\n",
    "Epochs: 1,095\n",
    "Training Loss: 0.001\n",
    "\n",
    "\n",
    "I was successfully able to get these parameters to converge on the circle dataset without making any changes. It converged in a shorter amout of time (1,095 epochs). I noticed that not only the hidden layers, but also the number of neurons per layer really makes a big difference. Using these same parameters but with fewer neurons per layer (especially the first layer) will lead to a model that will not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture a screen shot of your trained model and embed it \n",
    "\n",
    "\n",
    "![E5_image.png MISSING](./M8_E5.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "# M5 Exercise Question 6\n",
    "\n",
    "**Starting** with the Architecture you found as best in Exercise Q6, change data sets to the spiral configuration.\n",
    "\n",
    "![TFPG_Enclosed_DS.png MISSING](../images/TFPG_Spiral_DS.png)\n",
    "\n",
    "\n",
    "#### Set the hyperparameters as follows:\n",
    "**<span style=\"background:yellow\">Experiment</span>**\n",
    "\n",
    "#### Architecture:\n",
    "**<span style=\"background:yellow\">Locked to Final Architecture of Exercise Question 4.</span>**\n",
    "\n",
    "\n",
    "#### Task E6\n",
    "  Your goal is the get the lowest training and testing loss with the fewest epochs.\n",
    "  Do what ever it takes!\n",
    "  \n",
    "  **Q**: Describe your \"fun\" with this question!\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# E6 Write your Answer Below\n",
    "# ----------------------------\n",
    "\n",
    "hyperparameters 1:\n",
    "Learning rate: 0.003\n",
    "Activation: Tanh\n",
    "Regularization: None\n",
    "Regularization Rate: 0\n",
    "Epochs:\n",
    "Training Loss:\n",
    "\n",
    "Other hyperparemeters I tried varied the learning rate and regularization, but none resulted in better performance. These hyperparameters I believe will eventually converge, but would perhaps need to be running continuously for more than a day. Varying the learning rate and regularization led to models that would surpass the number of epochs as this one, yet have higher training and testing loss. Varying the activation resulted in models that would not converge at all. Therefore, these remain the best parameters I was able to find with this architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Capture a screen shot that includes data set, hyperparameters, architecture, and results model (decision surfaces).\n",
    "\n",
    "\n",
    "![E6_image.png MISSING](./M8_E6.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your notebook, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
