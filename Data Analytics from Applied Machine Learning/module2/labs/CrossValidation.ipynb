{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Cross-Validation\n",
    "\n",
    "In this lab you will learn about another important methodology for evaluating the machine learning model, \n",
    "namely **cross-validation**,\n",
    "which involves the splitting dataset into multiple folds then validate on one of them after training the model on the rest of the folds.\n",
    "This establishes a reliable performance measure that assesses how the model will likely to generalize to an independent data set.\n",
    "Cross-validation is widely used for estimating test error for the following reasons:\n",
    "\n",
    "1. Provides less biased evaluation, which in turn, helps you reduce overfitting.\n",
    "2. Provides reliable way to validate model when no explicit validation set is made available.\n",
    "\n",
    "We are going to use **Gaussian Naive Bayes model** to fit the **red wine quality** dataset and create 5-fold and 10-fold cross-validation then compare.\n",
    "There are different variations of cross-validation and we will take a closer look into **K-fold cross-validation**.\n",
    "\n",
    "sklearn API reference:\n",
    "\n",
    "+ [sklearn.model_selection.cross_val_score](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Load dataset from files into Panda data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "      <td>1599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.319637</td>\n",
       "      <td>0.527821</td>\n",
       "      <td>0.270976</td>\n",
       "      <td>2.538806</td>\n",
       "      <td>0.087467</td>\n",
       "      <td>15.874922</td>\n",
       "      <td>46.467792</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>3.311113</td>\n",
       "      <td>0.658149</td>\n",
       "      <td>10.422983</td>\n",
       "      <td>5.636023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.741096</td>\n",
       "      <td>0.179060</td>\n",
       "      <td>0.194801</td>\n",
       "      <td>1.409928</td>\n",
       "      <td>0.047065</td>\n",
       "      <td>10.460157</td>\n",
       "      <td>32.895324</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.154386</td>\n",
       "      <td>0.169507</td>\n",
       "      <td>1.065668</td>\n",
       "      <td>0.807569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.995600</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.260000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0.996750</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.200000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.997835</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
       "mean        8.319637          0.527821     0.270976        2.538806   \n",
       "std         1.741096          0.179060     0.194801        1.409928   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.390000     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.260000        2.200000   \n",
       "75%         9.200000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
       "mean      0.087467            15.874922             46.467792     0.996747   \n",
       "std       0.047065            10.460157             32.895324     0.001887   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             22.000000     0.995600   \n",
       "50%       0.079000            14.000000             38.000000     0.996750   \n",
       "75%       0.090000            21.000000             62.000000     0.997835   \n",
       "max       0.611000            72.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality  \n",
       "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
       "mean      3.311113     0.658149    10.422983     5.636023  \n",
       "std       0.154386     0.169507     1.065668     0.807569  \n",
       "min       2.740000     0.330000     8.400000     3.000000  \n",
       "25%       3.210000     0.550000     9.500000     5.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset location\n",
    "DATASET = '/dsa/data/all_datasets/wine-quality/winequality-red.csv'\n",
    "assert os.path.exists(DATASET)\n",
    "\n",
    "# Load and shuffle\n",
    "dataset = pd.read_csv(DATASET, sep=';').sample(frac = 1).reset_index(drop=True)\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with sklearn\n",
    "\n",
    "In this example, we use a few of the feature columns as input **X** and the `quality` column as output **y**.\n",
    "Then perform a 5-fold cross-validation using **cross_val_score()**,\n",
    "which splits the data into 5 folds (based on the **cv** argument).\n",
    "Then for each fold it fits the data on 4 folds and scores the 5th fold.\n",
    "Then it gives you the 5 scores from which you can calculate a mean and variance for the score.\n",
    "This potentially allows you to cross-validate in order to tune parameters and get an estimate of the score. \n",
    "\n",
    "Note that the cross-validation process involves fitting the model by definition,\n",
    "so you don't need to fit the model prior to cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55625   , 0.559375  , 0.646875  , 0.578125  , 0.57680251])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "# Convert the loaded dataset (data frame) into a multi-dimensional array with columns \n",
    "# 1,2,6,7,10 as input data\n",
    "X = dataset.iloc[:, [1,2,6,9,10]]\n",
    "    \n",
    "# Slice out the quality column as the expected value.\n",
    "y = np.array(dataset.quality)\n",
    "\n",
    "# Do the cross-validation\n",
    "sklearn.model_selection.cross_val_score(model, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above shows 5 scores from the 5-fold cross-validation.\n",
    "For each round of cross-validation, the model was fit on 4 of the folds and scored on the one held out.\n",
    "You should see different model scores, five in this case.\n",
    "This indicates that certain training instances validated against their test fold better than others.\n",
    "\n",
    "**Next, we will be sure to get very familiarized with this workflow by implementing our own. \n",
    "Then discuss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create folds\n",
    "\n",
    "The original dataset should be **randomly** sampled into equal-sized folds.\n",
    "But here the random resample was already done when we loaded the dataset previously.\n",
    "\n",
    "Now we split the data into 5 folds. \n",
    "This can be achieved using **array_split()** from numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function array_split in module numpy:\n",
      "\n",
      "array_split(ary, indices_or_sections, axis=0)\n",
      "    Split an array into multiple sub-arrays.\n",
      "    \n",
      "    Please refer to the ``split`` documentation.  The only difference\n",
      "    between these functions is that ``array_split`` allows\n",
      "    `indices_or_sections` to be an integer that does *not* equally\n",
      "    divide the axis. For an array of length l that should be split\n",
      "    into n sections, it returns l % n sub-arrays of size l//n + 1\n",
      "    and the rest of size l//n.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    split : Split array into multiple sub-arrays of equal size.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(8.0)\n",
      "    >>> np.array_split(x, 3)\n",
      "        [array([0.,  1.,  2.]), array([3.,  4.,  5.]), array([6.,  7.])]\n",
      "    \n",
      "    >>> x = np.arange(7.0)\n",
      "    >>> np.array_split(x, 3)\n",
      "        [array([0.,  1.,  2.]), array([3.,  4.]), array([5.,  6.])]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.array_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(320, 5), (320, 5), (320, 5), (320, 5), (319, 5)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_folds = np.array_split(X, 5) # split the array into 5 chunks by rows chunks (axis = 0)\n",
    "[i.shape for i in X_folds]   # check the number of instances per fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have around 1600 entries and 5 types of features in the input, so we have confirmed their shapes look good after splitting.\n",
    "The following demonstrates how **array_split()** behaves on dataset size that aren't evenly divisible by number of folds.\n",
    "This has ensured that the folds are divided as evenly as possible.\n",
    "Same could be achieved via array slicing, but would look more complicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 entries into 10 folds: [12, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "121 entries into 10 folds: [13, 12, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "122 entries into 10 folds: [13, 13, 12, 12, 12, 12, 12, 12, 12, 12]\n",
      "123 entries into 10 folds: [13, 13, 13, 12, 12, 12, 12, 12, 12, 12]\n",
      "124 entries into 10 folds: [13, 13, 13, 13, 12, 12, 12, 12, 12, 12]\n",
      "125 entries into 10 folds: [13, 13, 13, 13, 13, 12, 12, 12, 12, 12]\n",
      "126 entries into 10 folds: [13, 13, 13, 13, 13, 13, 12, 12, 12, 12]\n",
      "127 entries into 10 folds: [13, 13, 13, 13, 13, 13, 13, 12, 12, 12]\n",
      "128 entries into 10 folds: [13, 13, 13, 13, 13, 13, 13, 13, 12, 12]\n",
      "129 entries into 10 folds: [13, 13, 13, 13, 13, 13, 13, 13, 13, 12]\n"
     ]
    }
   ],
   "source": [
    "for t in range(120, 130):\n",
    "    print(t, 'entries into', 10, 'folds:', [i.shape[0] for i in np.array_split(np.zeros(t), 10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for Y folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(320,), (320,), (320,), (320,), (319,)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_folds = np.array_split(y, 5)\n",
    "[i.shape for i in y_folds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "For each round **i**:\n",
    "1. concatenate all folds _except fold **#i**_ to create the training set and fit the model\n",
    "2. then score the model based on the fold **#i** that was withheld from training.\n",
    "\n",
    "Each round is similar to what's been covered in Module 1: Train and Validate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 0 X_train (1279, 5) X_test (320, 5) y_train (1279,) y_test (320,)\n",
      "Score: 0.56\n",
      "CV 1 X_train (1279, 5) X_test (320, 5) y_train (1279,) y_test (320,)\n",
      "Score: 0.55\n",
      "CV 2 X_train (1279, 5) X_test (320, 5) y_train (1279,) y_test (320,)\n",
      "Score: 0.62\n",
      "CV 3 X_train (1279, 5) X_test (320, 5) y_train (1279,) y_test (320,)\n",
      "Score: 0.58\n",
      "CV 4 X_train (1280, 5) X_test (319, 5) y_train (1280,) y_test (319,)\n",
      "Score: 0.59\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    X_train = np.concatenate([X_folds[j] for j in range(5) if j!=i])\n",
    "    X_test = X_folds[i]\n",
    "    y_train = np.concatenate([y_folds[j] for j in range(5) if j!=i])\n",
    "    y_test = y_folds[i]\n",
    "    print('CV', i,\n",
    "          'X_train', X_train.shape, 'X_test', X_test.shape,\n",
    "          'y_train', y_train.shape, 'y_test', y_test.shape)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Score:', round(model.score(X_test, y_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting things together\n",
    "\n",
    "Now we can replicate the general functionality of **cross_val_score()** from sklearn, \n",
    "and have a better understanding of the cross-validation workflow.\n",
    "\n",
    "**Note:** As an exercise to help you get in the habit of congnitively processing code you read, instead of just running it, \n",
    "you could comment each code line with your interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our CV    : [0.556, 0.553, 0.616, 0.578, 0.589]\n",
      "sklearn CV: [0.556 0.559 0.647 0.578 0.577]\n"
     ]
    }
   ],
   "source": [
    "def cross_val_score(model, X, y, cv = 10):\n",
    "    X_folds = np.array_split(X, cv)\n",
    "    Y_folds = np.array_split(y, cv)\n",
    "    \n",
    "    for i in range(cv):\n",
    "        X_train = np.concatenate([X_folds[j] for j in range(cv) if j!=i])\n",
    "        X_test = X_folds[i]\n",
    "        y_train = np.concatenate([Y_folds[j] for j in range(cv) if j!=i])\n",
    "        y_test = y_folds[i]\n",
    "        model.fit(X_train, y_train)\n",
    "        yield round(model.score(X_test, y_test), 3)\n",
    "\n",
    "\n",
    "\n",
    "print('Our CV    :', list(cross_val_score(model, X, y, cv=5)))\n",
    "print('sklearn CV:', np.around(sklearn.model_selection.cross_val_score(model, X, y, cv=5), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold vs 10-fold cross-validation\n",
    "\n",
    "While the implementation of **k**-fold cross-validation is straightforward, \n",
    "it's important that we understand the strengths and limitations of this methodology before its application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold mean 0.5834855015673981 variance 0.001082942945050166\n",
      "10-fold mean 0.5791037735849056 variance 0.0011083787602349604\n"
     ]
    }
   ],
   "source": [
    "s5 = sklearn.model_selection.cross_val_score(model, X, y, cv=5)\n",
    "s10 = sklearn.model_selection.cross_val_score(model, X, y, cv=10)\n",
    "print('5-fold mean', np.mean(s5), 'variance', np.var(s5))\n",
    "print('10-fold mean', np.mean(s10), 'variance', np.var(s10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-fold scores [0.55625    0.559375   0.646875   0.578125   0.57680251]\n",
      "10-fold scores [0.56875    0.54375    0.55       0.53125    0.64375    0.6125\n",
      " 0.6125     0.58125    0.58125    0.56603774]\n"
     ]
    }
   ],
   "source": [
    "print('5-fold scores', s5)\n",
    "print('10-fold scores', s10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a known issue that cross-validated scores can have large variance especially on smaller datasets.\n",
    "Here we compare 5-fold vs 10-fold cross-validation, and 10-fold cross-validation has shown higher variance. \n",
    "\n",
    "+ Larger number of folds usually means less bias. However, as we use more folds, the testing dataset also gets smaller, and variance of cross-validation scores increases.\n",
    "+ Too large number of folds mean that only a low number of sample combinations is possible, thus limiting the number of iterations that are different. That is to say the training data/testing data for each round will have large overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f23574131d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: Second argument is a list-comprehension generated by running the for-loop of cross_val_score()\n",
    "plt.scatter([3,5,6,7,8,9,10],\n",
    "    [np.var(sklearn.model_selection.cross_val_score(model, X, y, cv=i))*100 for i in [3,5,6,7,8,9,10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above figure shows how variance of scores changes with respect to number of folds used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to lower the variance of the cross-validation result, you should iterate the cross-validation with new random splits.\n",
    "If possible, use a number of folds that is a divisor of the sample size.\n",
    "\n",
    "_Limitations of cross-validation are mostly relevant to small datasets._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this lab we learned about:\n",
    "\n",
    "+ Cross-validation workflow and its implementation\n",
    "+ Compared 5-fold vs 10-fold cross-validation\n",
    "+ Strengths and limitations of k-fold validation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
