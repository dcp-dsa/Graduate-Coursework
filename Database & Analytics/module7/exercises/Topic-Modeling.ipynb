{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will go over `realDonaldTrump_tweets` and perform topic modeling. Each line in this file is a tweet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1: Load the data**\n",
    "\n",
    "Consider each tweet as a document. Load the tweets. Strip away symbols and web links in the tweets. If the tweet becomes empty string after preprocessing, then discard the tweet from analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/dsa/data/all_datasets/linguistic/realDonaldTrump_tweets.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It was a great honor to have spoken before the countries of the world at the United Nations ', ' USAatUNGA UNGA  ', 'God bless the people of Mexico City  We are with you and will be there for you ', 'As President of the United States of America  I will ALWAYS put  AmericaFirst UNGA', 'Full remarks   ', 'Thehas great strength  amp  patience  but if it is forced to defend itself or its allies  we will have no choice but  ', 'RT  IvankaTrump  I have long respected India s accomplished and charismatic Foreign Minister  SushmaSwaraj  and it was an honor to meet her', 'Big day at the United Nations   many good things  and some tricky ones  happening  We have a great team  Big speech at 10 00 A M ', ' USAatUNGA  UNGA  ', 'We call for the full restoration of democracy and political freedoms in Venezuela  and we want it to happen very  v  ']\n"
     ]
    }
   ],
   "source": [
    "# load each tweet as a document\n",
    "\n",
    "with open(file_path, 'r') as f:\n",
    "    tweets = f.read().splitlines()\n",
    "    tweets = [re.sub(r'[^\\w]|https.*\\b', ' ', t) for t in tweets]\n",
    "\n",
    "print(tweets[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2: Create term frequency matrix for these tweets.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "term_frequency = count_vectorizer.fit_transform(tweets)\n",
    "feature_names = count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of term freq matrix = (3998, 6058)\n",
      "Num of features identified = 6058\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of term freq matrix = {term_frequency.shape}\")\n",
    "print(f\"Num of features identified = {len(feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3: Apply LDA topic modeling method with 5 topics**\n",
    "\n",
    "Fit an LDA model with 5 topics on these tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda.fit(term_frequency)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Print the top 10 words for each of the topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of topics = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([22.4773036 , 27.94216467,  1.19494424, ...,  0.20000724,\n",
       "        1.18896449,  0.20000306])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Num of topics = {len(lda.components_)}\")\n",
    "lda.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00am',\n",
       " '00pm',\n",
       " '00pme',\n",
       " '02',\n",
       " '10',\n",
       " '100',\n",
       " '100th',\n",
       " '100yrs',\n",
       " '109',\n",
       " '10am',\n",
       " '10k',\n",
       " '10p',\n",
       " '10pe',\n",
       " '10pm',\n",
       " '10pme',\n",
       " '11',\n",
       " '110',\n",
       " '113',\n",
       " '116',\n",
       " '119',\n",
       " '11a',\n",
       " '11pm',\n",
       " '11pme']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    \n",
    "    for topic_idx, term_weights in enumerate(model.components_):\n",
    "        sorted_indx = term_weights.argsort()\n",
    "\n",
    "        topk_words = [feature_names[i] for i in sorted_indx[-no_top_words :]]\n",
    "        print(f\"Topic {topic_idx}:\", end=None)\n",
    "        print(\";\".join(topk_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "foxandfriends;trump;amp;clinton;make;hillary;america;thank;rt;great\n",
      "Topic 1:\n",
      "china;tickets;president;watch;nytimes;failing;korea;north;amp;great\n",
      "Topic 2:\n",
      "just;trump;people;obamacare;news;clinton;fake;hillary;media;amp\n",
      "Topic 3:\n",
      "realdonaldtrump;country;today;just;amp;american;great;jobs;people;rt\n",
      "Topic 4:\n",
      "tonight;big;live;ohio;today;florida;tomorrow;amp;thank;join\n"
     ]
    }
   ],
   "source": [
    "display_topics(lda, feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5: Name each of the topic (No right answer)**\n",
    "\n",
    "After observing top-10 words in each topic, do these topics make sense to you? Can you name each of the topic? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 0: debate\n",
    "Topic 1: foreign policy\n",
    "Topic 2: domestic policy\n",
    "Topic 3: campaign\n",
    "Topic 4: rallies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6: Create a TFIDF matrix**\n",
    "\n",
    "Create TFIDF matrix for these tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(tweets)\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tfidf matrix = (3998, 6058)\n",
      "Num of features identified = 6058\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tfidf matrix = {tfidf.shape}\")\n",
    "print(f\"Num of features identified = {len(tfidf_feature_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 6: Apply NMF topic modeling with 5 topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_nmf.py:315: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  \"'nndsvda' in 1.1 (renaming of 0.26).\"), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=5, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=5, random_state=0)\n",
    "nmf.fit(term_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 7: Print the top 10 words for each of the topics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "people;today;vote;replace;obamacare;repeal;time;american;jobs;amp\n",
      "Topic 1:\n",
      "day;going;honor;big;today;state;people;make;america;great\n",
      "Topic 2:\n",
      "cnn;bad;fake;news;people;just;media;crooked;clinton;hillary\n",
      "Topic 3:\n",
      "potus;obama;hillaryclinton;new;teamtrump;foxandfriends;president;realdonaldtrump;trump;rt\n",
      "Topic 4:\n",
      "carolina;north;going;ohio;vote;join;florida;new;maga;thank\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 8: Perform a comparison between the topics identified by LDA and NMF methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "great 78.89910958182654\n",
      "amp 56.66443628383125\n",
      "north 55.244651225148786\n",
      "korea 46.98816793538438\n",
      "failing 44.262999777514366\n",
      "nytimes 40.66761631398792\n",
      "watch 36.916403716213324\n",
      "president 36.87990434595544\n",
      "tickets 35.10042679194915\n",
      "china 33.18958130309385\n"
     ]
    }
   ],
   "source": [
    "topic = lda.components_[1]  # take the corona topic\n",
    "no_top_words = 10\n",
    "\n",
    "weights_lda = {}\n",
    "for i in topic.argsort()[:-no_top_words - 1:-1]:\n",
    "    print(feature_names[i], topic[i])\n",
    "    weights_lda[feature_names[i]] = topic[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thank': 3.9436984526635266,\n",
       " 'maga': 0.6665638337722626,\n",
       " 'new': 0.49661884962907593,\n",
       " 'florida': 0.46414260713944505,\n",
       " 'join': 0.43832052060621124,\n",
       " 'vote': 0.3399501232859374,\n",
       " 'ohio': 0.33621088538121086,\n",
       " 'going': 0.3263236472326938,\n",
       " 'north': 0.30042240796729647,\n",
       " 'carolina': 0.28697893022218507}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = nmf.components_[4]  # take the corona topic\n",
    "no_top_words = 10\n",
    "\n",
    "weights_nmf = {}\n",
    "for i in topic.argsort()[:-no_top_words - 1:-1]:\n",
    "    weights_nmf[tfidf_feature_names[i]] = topic[i]\n",
    "weights_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>great</td>\n",
       "      <td>78.899110</td>\n",
       "      <td>thank</td>\n",
       "      <td>3.943698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amp</td>\n",
       "      <td>56.664436</td>\n",
       "      <td>maga</td>\n",
       "      <td>0.666564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>north</td>\n",
       "      <td>55.244651</td>\n",
       "      <td>new</td>\n",
       "      <td>0.496619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>korea</td>\n",
       "      <td>46.988168</td>\n",
       "      <td>florida</td>\n",
       "      <td>0.464143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failing</td>\n",
       "      <td>44.263000</td>\n",
       "      <td>join</td>\n",
       "      <td>0.438321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nytimes</td>\n",
       "      <td>40.667616</td>\n",
       "      <td>vote</td>\n",
       "      <td>0.339950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>watch</td>\n",
       "      <td>36.916404</td>\n",
       "      <td>ohio</td>\n",
       "      <td>0.336211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>president</td>\n",
       "      <td>36.879904</td>\n",
       "      <td>going</td>\n",
       "      <td>0.326324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tickets</td>\n",
       "      <td>35.100427</td>\n",
       "      <td>north</td>\n",
       "      <td>0.300422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>china</td>\n",
       "      <td>33.189581</td>\n",
       "      <td>carolina</td>\n",
       "      <td>0.286979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1         0         1\n",
       "0      great  78.899110     thank  3.943698\n",
       "1        amp  56.664436      maga  0.666564\n",
       "2      north  55.244651       new  0.496619\n",
       "3      korea  46.988168   florida  0.464143\n",
       "4    failing  44.263000      join  0.438321\n",
       "5    nytimes  40.667616      vote  0.339950\n",
       "6      watch  36.916404      ohio  0.336211\n",
       "7  president  36.879904     going  0.326324\n",
       "8    tickets  35.100427     north  0.300422\n",
       "9      china  33.189581  carolina  0.286979"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame(weights_lda.items())\n",
    "df2 = pd.DataFrame(weights_nmf.items())\n",
    "\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "11.9886px",
    "width": "251.989px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
