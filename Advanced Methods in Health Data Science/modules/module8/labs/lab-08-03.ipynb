{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 Lab 3  - Scikit-learn preprocessing for itemization\n",
    "\n",
    "Sometimes the data the you have are not in a format conducive to machine learning, or a particular algorithm that you wish to use.  Some common preprocessing that might need to take place are concepts like itemization of continuous features (e.g. Age as a continuous value can be categorized into buckets by gae range).  You may also need to represent categorical values as dummy variables (common for regressions).  You may wish to convert continuous values into a binary variable, such as above a threhold or below it.  Finally, some data may be textual, and to process this kind of data you may need to convert it into a numeric representation of some kind.\n",
    "\n",
    "We will use the breast cancer dataset to illustrate these concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as d\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = d.load_breast_cancer()\n",
    "data = pd.DataFrame(bc.data, columns = bc.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a binary feature from continuous data\n",
    "\n",
    "Often you will have data that are continuous in nature, like some measurement, that can take on an infinite or large number of possible values.  Think about numbers with decimal points, such as temperature, or even integer values with a large range like annual salary.  It can be useful to treat this data in a binary fashion, i.e. True or False, Above or Below, High or Low, etc.\n",
    "\n",
    "To transform a continuous feature into a binary feature is straighforward.  You first need to know the cutoff point that marks one value from the other.  This can be obtained from subject matter experts or similar ways.  You could also split on the mean, median, mode, or any other central measure, although the value of doing that will depend on your goals.\n",
    "\n",
    "Below, we will binarize a column by splitting on the mean of the feature.  The [Binarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html) class expects an array of values, so we perform some transformation of the pandas Series into an array using `data['mean radius'].values.reshape(-1,1)`.  `.values` gives us a one dimensional array and `.reshape(-1,1)` turns it into the 2d array form that the Binarizer class expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.127291739894552\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius bin</th>\n",
       "      <th>mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1.0</td>\n",
       "      <td>20.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius bin  mean radius\n",
       "0                1.0        17.99\n",
       "1                1.0        20.57\n",
       "2                1.0        19.69\n",
       "3                0.0        11.42\n",
       "4                1.0        20.29\n",
       "..               ...          ...\n",
       "564              1.0        21.56\n",
       "565              1.0        20.13\n",
       "566              1.0        16.60\n",
       "567              1.0        20.60\n",
       "568              0.0         7.76\n",
       "\n",
       "[569 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binarized = preprocessing.Binarizer(data['mean radius'].mean()).fit_transform(data['mean radius'].values.reshape(-1,1))\n",
    "data['mean radius bin'] = binarized\n",
    "print(data['mean radius'].mean())\n",
    "display(data[['mean radius bin', 'mean radius']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a categorical feature from continuous data (discretization)\n",
    "This process is similar to binarize, however instead of just two possible values, we will bucket the continuous variable into multiple categories.  This technique is useful to reduce the number of possible values your learning models have to deal with.  Some algorithms, like association rule mining, will only work with disctretized data.\n",
    "\n",
    "There are a couple of approaches that can be taken.  The first approach is to dump the values into a set number of bins.  This is a straighforward approach that requires you to choose how many bins you want, the desired composition of the bins, and the encoding method.  We will use the [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html).  \n",
    "\n",
    "Below, we will create 3 bins of equal range using the `strategy='uniform'` (based on the range of data: min to max).  We also specify ordinal output, so that the new bins are numbered and encoded in a single column.  With these parameters, we are essentially creating a histogram.\n",
    "\n",
    "We do the same reshaping process as above.  Then we add the data back to our pandas data frame, group by the new column, and get a count of each of the bins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius ordinal\n",
       "0.0    338\n",
       "1.0    209\n",
       "2.0     22\n",
       "Name: mean radius ordinal, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_bins = 3\n",
    "\n",
    "discrete = preprocessing.KBinsDiscretizer(n_bins=num_bins, encode='ordinal', strategy='uniform').fit_transform(data['mean radius'].values.reshape(-1,1))\n",
    "\n",
    "data['mean radius ordinal'] = discrete\n",
    "data.groupby('mean radius ordinal')['mean radius ordinal'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try the other strategies to see the difference in bin sizes.\n",
    "\n",
    "Quantile will create bins that contain the same number of data points (as close as possible).\n",
    "\n",
    "KMeans will use 1-dimensional clustering to produce the bins, so values that are closer together will be in one bin, and farther apart will be in spearate bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius quantile\n",
       "0.0    189\n",
       "1.0    190\n",
       "2.0    190\n",
       "Name: mean radius quantile, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "mean radius kmeans\n",
       "0.0    249\n",
       "1.0    212\n",
       "2.0    108\n",
       "Name: mean radius kmeans, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discrete = preprocessing.KBinsDiscretizer(n_bins=num_bins, encode='ordinal', strategy='quantile').fit_transform(data['mean radius'].values.reshape(-1,1))\n",
    "\n",
    "data['mean radius quantile'] = discrete\n",
    "display(data.groupby('mean radius quantile')['mean radius quantile'].count())\n",
    "\n",
    "discrete = preprocessing.KBinsDiscretizer(n_bins=num_bins, encode='ordinal', strategy='kmeans').fit_transform(data['mean radius'].values.reshape(-1,1))\n",
    "\n",
    "data['mean radius kmeans'] = discrete\n",
    "display(data.groupby('mean radius kmeans')['mean radius kmeans'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see each strategy produces very different results.  With quantile you get as close to the same points in each bin as possible, so it is the range of each bin that changes.  With KMeans, you will get data that is clustered around 3 points on a 1-d line, so both the counts and the bin ranges vary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a categorical feature from continuous data (discretization) with custom intervals\n",
    "KBinsDiscretizer is powerful, but it will not accept custom intervals for creating bins.  If you have some domain knowledge about your continuous data and want to discretize it using that knowledge, then you can use the Pandas cut method.\n",
    "\n",
    "Suppose we have some knoweldge that a `mean radius` <= 11 is \"small\", <= 14 is \"medium\", and everything else is \"large\".  We want to discretize on the specific values.  Pandas [cut](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html) will allow us to specify these cut points.\n",
    "\n",
    "`bins=[0, 11, 14, 99999999]` defines the edges of our data.  We start with zero since a growth radius cannot be negative.  Next is the top range for our first category.  We've defined the first category as (> 0 and <= 11).  The second category is (> 11 and <= 14), and the last category is (> 14 and <= 99999999).  We use a suitably large value to cover the \"everything else\" case.  We then give a label to each of these ranges using the `labels` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius custom</th>\n",
       "      <th>mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>17.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20.570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>20.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>12.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>18.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13.710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>13.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>12.460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>16.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>15.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>19.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>15.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>13.730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>14.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>14.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>16.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>19.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>13.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>13.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>9.504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>15.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>21.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>16.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>17.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>14.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>18.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>15.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>17.570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius custom  mean radius\n",
       "0                   2       17.990\n",
       "1                   2       20.570\n",
       "2                   2       19.690\n",
       "3                   1       11.420\n",
       "4                   2       20.290\n",
       "5                   1       12.450\n",
       "6                   2       18.250\n",
       "7                   1       13.710\n",
       "8                   1       13.000\n",
       "9                   1       12.460\n",
       "10                  2       16.020\n",
       "11                  2       15.780\n",
       "12                  2       19.170\n",
       "13                  2       15.850\n",
       "14                  1       13.730\n",
       "15                  2       14.540\n",
       "16                  2       14.680\n",
       "17                  2       16.130\n",
       "18                  2       19.810\n",
       "19                  1       13.540\n",
       "20                  1       13.080\n",
       "21                  0        9.504\n",
       "22                  2       15.340\n",
       "23                  2       21.160\n",
       "24                  2       16.650\n",
       "25                  2       17.140\n",
       "26                  2       14.580\n",
       "27                  2       18.610\n",
       "28                  2       15.300\n",
       "29                  2       17.570"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['mean radius custom'] = pd.cut(data['mean radius'], bins=[0, 11, 14, 99999999], labels=[0, 1, 2])\n",
    "data[['mean radius custom', 'mean radius']].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dummy variables from categorical data\n",
    "Continuing with the KBinsDiscretizer class, we will now investigate the other options for the `encode` parameter.  Previously we looked at `ordinal`, which output a single column.  Now we will examine the \"one hot\" encoding options.\n",
    "\n",
    "The term \"one hot\" has its roots in digital circuitry, in which only one of a set of digital lines has voltage applied in order to indicate some input or output.  Translated to data, we will get multiple binary columns to represent ordinal values, as in the below image.\n",
    "\n",
    "<img src=\"../resources/one-hot-example.jpg\" alt=\"Example of one-hot encoding\" title=\"Example of one-hot encoding\" />\n",
    "\n",
    "One-hot encoding is a necessary format for many types of machine learning algorithms.  Categorical data often can't be used directly in machine learning.  Primarily this is because numeric categorical data do not have mathematical properties like less than or greater than (although you can create categorical data where order is important: ordinal).  Also, it does not make sense to add, subtract, multiply, or divide categorical data.  There are a few algorithms that can use some types of categorical data directly (decision trees can use ordinal categoricals directly), however most machine learning will require one-hot encoding.\n",
    "\n",
    "Let's see what that will look like with our sample data.  We will create a one-hot dense encoding.  Dense encoding is used machine learning and data mining techniques techniques such as artificial neural networks and association rule mining.\n",
    "\n",
    "For comparison we will append our previously created ordinal representation and the original data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>mean radius ordinal</th>\n",
       "      <th>mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2  mean radius ordinal  mean radius\n",
       "0  0.0  1.0  0.0                  1.0        17.99\n",
       "1  0.0  1.0  0.0                  1.0        20.57\n",
       "2  0.0  1.0  0.0                  1.0        19.69\n",
       "3  1.0  0.0  0.0                  0.0        11.42\n",
       "4  0.0  1.0  0.0                  1.0        20.29\n",
       "5  1.0  0.0  0.0                  0.0        12.45\n",
       "6  0.0  1.0  0.0                  1.0        18.25\n",
       "7  1.0  0.0  0.0                  0.0        13.71\n",
       "8  1.0  0.0  0.0                  0.0        13.00\n",
       "9  1.0  0.0  0.0                  0.0        12.46"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "discrete = preprocessing.KBinsDiscretizer(n_bins=num_bins, encode='onehot-dense', strategy='uniform').fit_transform(data['mean radius'].values.reshape(-1,1))\n",
    "\n",
    "mean_radius_onehot = pd.DataFrame(discrete)\n",
    "mean_radius_onehot['mean radius ordinal'] = data['mean radius ordinal']\n",
    "mean_radius_onehot['mean radius'] = data['mean radius']\n",
    "display(mean_radius_onehot.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using one-hot encoded variables in statistical regression, you must drop one of the dummy varaibles.  This is commonly the first one.  The above table illustrates why k-1 encoding is necessary in regression.  Recall that one of the assumptions for regression is that there is no multi-colinearity in the independent variables.  From the table above we can see that columns 1 and 2 together predict the value of column 0 (when column 1 and 2 are both zero, column 0 will be one), leading to violation of this assumption.\n",
    "\n",
    "We can modify our data frame easily enough with the drop method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>mean radius ordinal</th>\n",
       "      <th>mean radius</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    2  mean radius ordinal  mean radius\n",
       "0  1.0  0.0                  1.0        17.99\n",
       "1  1.0  0.0                  1.0        20.57\n",
       "2  1.0  0.0                  1.0        19.69\n",
       "3  0.0  0.0                  0.0        11.42\n",
       "4  1.0  0.0                  1.0        20.29\n",
       "5  0.0  0.0                  0.0        12.45\n",
       "6  1.0  0.0                  1.0        18.25\n",
       "7  0.0  0.0                  0.0        13.71\n",
       "8  0.0  0.0                  0.0        13.00\n",
       "9  0.0  0.0                  0.0        12.46"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_radius_onehot.drop(0, axis='columns').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that when `mean radius ordinal` is zero, then all of the one-hot encoded columns are also zero.  This condition implies that the categorical value is `0`.  We don't need the column we dropped to make this inference, so we've solved the multi-colinearity violation and we haven't lost any information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the relationship between which of the columns `0`, `1`, and `2` contain the \"on\" value of 1 based on the value of the ordinal encoding.  These columns are mutually exclusive, so the set will only ever represent one category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a categorical feature from labeled data\n",
    "Sometimes you will get data that has been labeled for you.  The labels may be text or numeric.  To perform machine learning, it is necessary to convert the text data into categorical data, and then possibly into dummy variables as we already discussed.\n",
    "\n",
    "This will not be a full fledged introduction to text mining, but rather a simple text to numeric category conversion.\n",
    "\n",
    "For this lab we will be using a dataset that contains text based categorical data, the [NCHS - Leading Causes of Death: United States](https://catalog.data.gov/dataset/age-adjusted-death-rates-for-the-top-10-leading-causes-of-death-united-states-2013), which contains the top 10 leading causes of death in the US from 1999 to 2016.  There are three text based categorical columns in the data:\n",
    "* 113 Cause Name - The cause of death from the [CDC's list of 113 causes of death](https://www.cdc.gov/nchs/data/dvs/im9_2002.pdf.pdf)\n",
    "* Cause Name - a shortened cause of death\n",
    "* State - The state to which the data apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>113 Cause Name</th>\n",
       "      <th>Cause Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2755</td>\n",
       "      <td>55.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>439</td>\n",
       "      <td>63.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>4010</td>\n",
       "      <td>54.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1604</td>\n",
       "      <td>51.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>California</td>\n",
       "      <td>13213</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year                                     113 Cause Name  \\\n",
       "0  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "1  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "2  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "3  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "4  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "\n",
       "               Cause Name       State  Deaths  Age-adjusted Death Rate  \n",
       "0  Unintentional injuries     Alabama    2755                     55.5  \n",
       "1  Unintentional injuries      Alaska     439                     63.1  \n",
       "2  Unintentional injuries     Arizona    4010                     54.2  \n",
       "3  Unintentional injuries    Arkansas    1604                     51.8  \n",
       "4  Unintentional injuries  California   13213                     32.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../resources/NCHS_-_Leading_Causes_of_Death__United_States.csv', delimiter=',')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will utilize the [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) class from sklearn.  We are going to save the instantiated OrdinalEncoder class so that we can extract the categories from it after transforming our data.  We will also cast the numpy array results back into a Pandas DataFrame.\n",
    "\n",
    "First, we'll just pass our whole data set into the encoder.  This is probably a terrible idea, because some of our data is not text based.  Let's see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>113 Cause Name</th>\n",
       "      <th>Cause Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2318.0</td>\n",
       "      <td>512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>410.0</td>\n",
       "      <td>583.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2895.0</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>475.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4336.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  113 Cause Name  Cause Name  State  Deaths  Age-adjusted Death Rate\n",
       "0  17.0             0.0        10.0    0.0  2318.0                    512.0\n",
       "1  17.0             0.0        10.0    1.0   410.0                    583.0\n",
       "2  17.0             0.0        10.0    2.0  2895.0                    499.0\n",
       "3  17.0             0.0        10.0    3.0  1472.0                    475.0\n",
       "4  17.0             0.0        10.0    4.0  4336.0                    277.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = preprocessing.OrdinalEncoder()\n",
    "new_data = pd.DataFrame(encoder.fit_transform(data), columns=data.columns)\n",
    "display(new_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, looks like we got every column encoded.  Not terribly useful...and potentially misleading.  The `Deaths` column data actually looks legitimate at first glance, and one might mistakenly think it is a count of deaths rather than a categorical representation of death count.  \n",
    "\n",
    "We can see the categories assigned by examining a property on the encoder.  The position in the category array equals the category number we find in our transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,\n",
       "        2010, 2011, 2012, 2013, 2014, 2015, 2016], dtype=object),\n",
       " array(['Accidents (unintentional injuries) (V01-X59,Y85-Y86)',\n",
       "        'All Causes', \"Alzheimer's disease (G30)\",\n",
       "        'Cerebrovascular diseases (I60-I69)',\n",
       "        'Chronic lower respiratory diseases (J40-J47)',\n",
       "        'Diabetes mellitus (E10-E14)',\n",
       "        'Diseases of heart (I00-I09,I11,I13,I20-I51)',\n",
       "        'Influenza and pneumonia (J09-J18)',\n",
       "        'Intentional self-harm (suicide) (*U03,X60-X84,Y87.0)',\n",
       "        'Malignant neoplasms (C00-C97)',\n",
       "        'Nephritis, nephrotic syndrome and nephrosis (N00-N07,N17-N19,N25-N27)'],\n",
       "       dtype=object),\n",
       " array(['All causes', \"Alzheimer's disease\", 'CLRD', 'Cancer', 'Diabetes',\n",
       "        'Heart disease', 'Influenza and pneumonia', 'Kidney disease',\n",
       "        'Stroke', 'Suicide', 'Unintentional injuries'], dtype=object),\n",
       " array(['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California',\n",
       "        'Colorado', 'Connecticut', 'Delaware', 'District of Columbia',\n",
       "        'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana',\n",
       "        'Iowa', 'Kansas', 'Kentucky', 'Louisiana', 'Maine', 'Maryland',\n",
       "        'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n",
       "        'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire',\n",
       "        'New Jersey', 'New Mexico', 'New York', 'North Carolina',\n",
       "        'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n",
       "        'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee',\n",
       "        'Texas', 'United States', 'Utah', 'Vermont', 'Virginia',\n",
       "        'Washington', 'West Virginia', 'Wisconsin', 'Wyoming'],\n",
       "       dtype=object),\n",
       " array([21, 23, 24, ..., 2596993, 2626418, 2712630], dtype=object),\n",
       " array([2.6, 3.7, 3.8, ..., 1051.9, 1061.2, 1087.3], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, so lets just be specific, and encode only the text based columns that we care about.  At the same time, we can control the resulting data type.  The default is float64, but we don't really need decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>113 Cause Name</th>\n",
       "      <th>Cause Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Deaths</th>\n",
       "      <th>Age-adjusted Death Rate</th>\n",
       "      <th>113 Cause Name Enc</th>\n",
       "      <th>Cause Name Enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2755</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>439</td>\n",
       "      <td>63.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>4010</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>1604</td>\n",
       "      <td>51.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>California</td>\n",
       "      <td>13213</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>2880</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1978</td>\n",
       "      <td>50.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>516</td>\n",
       "      <td>52.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>401</td>\n",
       "      <td>58.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Florida</td>\n",
       "      <td>12561</td>\n",
       "      <td>54.9</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>4701</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>577</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>849</td>\n",
       "      <td>49.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>5508</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3496</td>\n",
       "      <td>51.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>1608</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>1444</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>3194</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2710</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Maine</td>\n",
       "      <td>909</td>\n",
       "      <td>62.4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>2271</td>\n",
       "      <td>35.7</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>3831</td>\n",
       "      <td>52.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>5313</td>\n",
       "      <td>50.5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2697</td>\n",
       "      <td>43.8</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>1803</td>\n",
       "      <td>59.2</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>3625</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Montana</td>\n",
       "      <td>626</td>\n",
       "      <td>54.1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Nebraska</td>\n",
       "      <td>772</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>1395</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2016</td>\n",
       "      <td>Accidents (unintentional injuries) (V01-X59,Y8...</td>\n",
       "      <td>Unintentional injuries</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>924</td>\n",
       "      <td>66.6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year                                     113 Cause Name  \\\n",
       "0   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "1   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "2   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "3   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "4   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "5   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "6   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "7   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "8   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "9   2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "10  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "11  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "12  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "13  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "14  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "15  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "16  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "17  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "18  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "19  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "20  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "21  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "22  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "23  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "24  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "25  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "26  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "27  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "28  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "29  2016  Accidents (unintentional injuries) (V01-X59,Y8...   \n",
       "\n",
       "                Cause Name                 State  Deaths  \\\n",
       "0   Unintentional injuries               Alabama    2755   \n",
       "1   Unintentional injuries                Alaska     439   \n",
       "2   Unintentional injuries               Arizona    4010   \n",
       "3   Unintentional injuries              Arkansas    1604   \n",
       "4   Unintentional injuries            California   13213   \n",
       "5   Unintentional injuries              Colorado    2880   \n",
       "6   Unintentional injuries           Connecticut    1978   \n",
       "7   Unintentional injuries              Delaware     516   \n",
       "8   Unintentional injuries  District of Columbia     401   \n",
       "9   Unintentional injuries               Florida   12561   \n",
       "10  Unintentional injuries               Georgia    4701   \n",
       "11  Unintentional injuries                Hawaii     577   \n",
       "12  Unintentional injuries                 Idaho     849   \n",
       "13  Unintentional injuries              Illinois    5508   \n",
       "14  Unintentional injuries               Indiana    3496   \n",
       "15  Unintentional injuries                  Iowa    1608   \n",
       "16  Unintentional injuries                Kansas    1444   \n",
       "17  Unintentional injuries              Kentucky    3194   \n",
       "18  Unintentional injuries             Louisiana    2710   \n",
       "19  Unintentional injuries                 Maine     909   \n",
       "20  Unintentional injuries              Maryland    2271   \n",
       "21  Unintentional injuries         Massachusetts    3831   \n",
       "22  Unintentional injuries              Michigan    5313   \n",
       "23  Unintentional injuries             Minnesota    2697   \n",
       "24  Unintentional injuries           Mississippi    1803   \n",
       "25  Unintentional injuries              Missouri    3625   \n",
       "26  Unintentional injuries               Montana     626   \n",
       "27  Unintentional injuries              Nebraska     772   \n",
       "28  Unintentional injuries                Nevada    1395   \n",
       "29  Unintentional injuries         New Hampshire     924   \n",
       "\n",
       "    Age-adjusted Death Rate  113 Cause Name Enc  Cause Name Enc  \n",
       "0                      55.5                   0              10  \n",
       "1                      63.1                   0              10  \n",
       "2                      54.2                   0              10  \n",
       "3                      51.8                   0              10  \n",
       "4                      32.0                   0              10  \n",
       "5                      51.2                   0              10  \n",
       "6                      50.3                   0              10  \n",
       "7                      52.4                   0              10  \n",
       "8                      58.3                   0              10  \n",
       "9                      54.9                   0              10  \n",
       "10                     45.8                   0              10  \n",
       "11                     35.3                   0              10  \n",
       "12                     49.5                   0              10  \n",
       "13                     41.0                   0              10  \n",
       "14                     51.6                   0              10  \n",
       "15                     45.8                   0              10  \n",
       "16                     45.7                   0              10  \n",
       "17                     71.0                   0              10  \n",
       "18                     57.4                   0              10  \n",
       "19                     62.4                   0              10  \n",
       "20                     35.7                   0              10  \n",
       "21                     52.8                   0              10  \n",
       "22                     50.5                   0              10  \n",
       "23                     43.8                   0              10  \n",
       "24                     59.2                   0              10  \n",
       "25                     57.0                   0              10  \n",
       "26                     54.1                   0              10  \n",
       "27                     37.0                   0              10  \n",
       "28                     46.0                   0              10  \n",
       "29                     66.6                   0              10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_columns = ['113 Cause Name', 'Cause Name'] # these are the columns we want to encode\n",
    "encoder = preprocessing.OrdinalEncoder(dtype=np.int32) # create a new encoder.  The one we already have is trained already, and we want to retrain it, and tell it to use a different data type\n",
    "new_data = pd.DataFrame(encoder.fit_transform(data[text_columns]), columns=text_columns)\n",
    "data = data.join(new_data,rsuffix = ' Enc') # join the encoded back to original.  rsuffix will add the specified text as a suffix to the columns from new_data to avoid duplicate column names\n",
    "display(data.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Accidents (unintentional injuries) (V01-X59,Y85-Y86)',\n",
       "        'All Causes', \"Alzheimer's disease (G30)\",\n",
       "        'Cerebrovascular diseases (I60-I69)',\n",
       "        'Chronic lower respiratory diseases (J40-J47)',\n",
       "        'Diabetes mellitus (E10-E14)',\n",
       "        'Diseases of heart (I00-I09,I11,I13,I20-I51)',\n",
       "        'Influenza and pneumonia (J09-J18)',\n",
       "        'Intentional self-harm (suicide) (*U03,X60-X84,Y87.0)',\n",
       "        'Malignant neoplasms (C00-C97)',\n",
       "        'Nephritis, nephrotic syndrome and nephrosis (N00-N07,N17-N19,N25-N27)'],\n",
       "       dtype=object),\n",
       " array(['All causes', \"Alzheimer's disease\", 'CLRD', 'Cancer', 'Diabetes',\n",
       "        'Heart disease', 'Influenza and pneumonia', 'Kidney disease',\n",
       "        'Stroke', 'Suicide', 'Unintentional injuries'], dtype=object)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(encoder.categories_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you can one-hot encode these categorical features as needed.\n",
    "There are other sklearn Encoders that can create categorical data from text columns:\n",
    "* [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) - Take string data right to one-hot encoding.  It has a lot of parameters to configure.\n",
    "* [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) - Work on one feature at a time\n",
    "* [LabelBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) - Similar to one-hot encoder but designed to be used with multi-class classification approaches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
