{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8 Lab 2 - Filtering association rules\n",
    "\n",
    "One of the main challenges with using association rule mining is dealing with the potentially immense set of rules that are generated.  In many cases, it is easy to generate millions of association rules, which is both unwieldy and not useful.\n",
    "\n",
    "In this lab you will learn how to filter association rules so that you can make sense of them and put them to further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlxtend in /opt/conda/lib/python3.7/site-packages (0.19.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.17.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from mlxtend) (41.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (1.2.1)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (3.1.1)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/conda/lib/python3.7/site-packages (from mlxtend) (0.25.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.2->mlxtend) (2019.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->mlxtend) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "!{sys.executable} -m pip install mlxtend\n",
    "import mlxtend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "We will continue to use the sample breast cancer data set to generate our rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>-0.014719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>-1.001659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>-0.144580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>0.699513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>-0.222496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6    target  \n",
       "0 -0.002592  0.019908 -0.017646 -0.014719  \n",
       "1 -0.039493 -0.068330 -0.092204 -1.001659  \n",
       "2 -0.002592  0.002864 -0.025930 -0.144580  \n",
       "3  0.034309  0.022692 -0.009362  0.699513  \n",
       "4 -0.002592 -0.031991 -0.046641 -0.222496  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn.datasets as d\n",
    "from sklearn import preprocessing\n",
    "\n",
    "db = d.load_diabetes()\n",
    "target = preprocessing.scale(db.target)\n",
    "data = pd.DataFrame(np.c_[db.data, target], columns = np.append(db.feature_names, ['target']))\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for ARM\n",
    "We will apply the same preprocessing as in lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  age  bmi  bp  s1  s2  s3  s4  s5  s6  target\n",
       "0    1    3    4   2   1   1   0   1   2   2       1\n",
       "1    0    2    0   1   2   1   3   0   0   0       0\n",
       "2    1    4    4   2   1   1   1   1   2   1       1\n",
       "3    0    0    2   1   2   2   0   2   2   2       2\n",
       "4    0    2    1   2   2   2   2   1   1   1       1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "binary_col = ['sex']\n",
    "quant_col = ['age', 'bmi']\n",
    "kmeans_col = ['bp', 's1', 's2', 's3', 's4', 's5', 's6', 'target']\n",
    "\n",
    "binary_data = preprocessing.Binarizer(0).fit_transform(data[binary_col].values.reshape(-1,1))\n",
    "quant_data = preprocessing.KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile').fit_transform(data[quant_col])\n",
    "kmeans_data = preprocessing.KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='kmeans').fit_transform(data[kmeans_col])\n",
    "\n",
    "# join back into a single dataframe.  hstack the individual numpy arrays together.  force datatype to be int\n",
    "data = pd.DataFrame(np.hstack((binary_data, quant_data, kmeans_data)), columns = binary_col+quant_col+kmeans_col, dtype=int)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode the data\n",
    "This will produce the required format to use the mlextend package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_0</th>\n",
       "      <th>sex_1</th>\n",
       "      <th>age_0</th>\n",
       "      <th>age_1</th>\n",
       "      <th>age_2</th>\n",
       "      <th>age_3</th>\n",
       "      <th>age_4</th>\n",
       "      <th>bmi_0</th>\n",
       "      <th>bmi_1</th>\n",
       "      <th>bmi_2</th>\n",
       "      <th>...</th>\n",
       "      <th>s6_0</th>\n",
       "      <th>s6_1</th>\n",
       "      <th>s6_2</th>\n",
       "      <th>s6_3</th>\n",
       "      <th>s6_4</th>\n",
       "      <th>target_0</th>\n",
       "      <th>target_1</th>\n",
       "      <th>target_2</th>\n",
       "      <th>target_3</th>\n",
       "      <th>target_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_0  sex_1  age_0  age_1  age_2  age_3  age_4  bmi_0  bmi_1  bmi_2  ...  \\\n",
       "0      0      1      0      0      0      1      0      0      0      0  ...   \n",
       "1      1      0      0      0      1      0      0      1      0      0  ...   \n",
       "2      0      1      0      0      0      0      1      0      0      0  ...   \n",
       "3      1      0      1      0      0      0      0      0      0      1  ...   \n",
       "4      1      0      0      0      1      0      0      0      1      0  ...   \n",
       "\n",
       "   s6_0  s6_1  s6_2  s6_3  s6_4  target_0  target_1  target_2  target_3  \\\n",
       "0     0     0     1     0     0         0         1         0         0   \n",
       "1     1     0     0     0     0         1         0         0         0   \n",
       "2     0     1     0     0     0         0         1         0         0   \n",
       "3     0     0     1     0     0         0         0         1         0   \n",
       "4     0     1     0     0     0         0         1         0         0   \n",
       "\n",
       "   target_4  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns = data.columns)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the frequent itemsets \n",
    "This step will produce the frequent itemsets from which we can extract association rules.  We are using a small min_support to get more frequent itemsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.531674</td>\n",
       "      <td>(sex_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.468326</td>\n",
       "      <td>(sex_1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>(age_0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205882</td>\n",
       "      <td>(age_1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183258</td>\n",
       "      <td>(age_2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52423</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s3_1, s4_0, s6_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52424</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>(s5_0, s1_0, target_0, s3_1, s4_0, age_0, bp_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52425</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>(s5_0, s1_0, target_0, s3_1, s4_0, s6_1, bp_1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52426</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s3_1, s4_0, age_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52427</th>\n",
       "      <td>0.006787</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s3_1, s4_0, s6_1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52428 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        support                                           itemsets\n",
       "0      0.531674                                            (sex_0)\n",
       "1      0.468326                                            (sex_1)\n",
       "2      0.192308                                            (age_0)\n",
       "3      0.205882                                            (age_1)\n",
       "4      0.183258                                            (age_2)\n",
       "...         ...                                                ...\n",
       "52423  0.006787  (s5_0, s1_0, target_0, sex_1, s3_1, s4_0, s6_1...\n",
       "52424  0.006787  (s5_0, s1_0, target_0, s3_1, s4_0, age_0, bp_1...\n",
       "52425  0.006787  (s5_0, s1_0, target_0, s3_1, s4_0, s6_1, bp_1,...\n",
       "52426  0.006787  (s5_0, s1_0, target_0, sex_1, s3_1, s4_0, age_...\n",
       "52427  0.006787  (s5_0, s1_0, target_0, sex_1, s3_1, s4_0, s6_1...\n",
       "\n",
       "[52428 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "frequent_itemsets = apriori(data, min_support=0.005, use_colnames=True)\n",
    "display(frequent_itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the association rules\n",
    "We will use confidence to extract the rules from the frequent itemsets.  \n",
    "\n",
    "Recall that these are the available metrics we can use:\n",
    "* **support**: the support for the antecedent set plus the consequent set\n",
    "* **confidence**: the support for the antecedent set plus the consequent set divided by the support for the antecedent set.  This is the proportion of transactions that contain the antecedent that also contain the consequent\n",
    "* **lift**: The ratio of the rule's confidence to the unconditional probability of the consequent.  It is a measure of dependence of the antecedent and consequent.  Items are likely correlated if lift > 1.  If lift < 1, then it implies a negative correlation.\n",
    "* **leverage**: Measures how much more often the antecedent and consequent appear together than if the antecedent and consequent were independent.  This is a way to look for dependencies between the antecedent and consequent.\n",
    "* **conviction**: This is the ratio of the frequency that the antecedent occurs without the consequent (1 - consequent support), divided by the observed frequency of incorrect predictions (1 - confidence). A value above 1 indicates the frequency that a given rule would be incorrect if the antecedent and consequent were associated purely by random chance. The value is unbounded, and can range from 0.5 to infinity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(age_0)</td>\n",
       "      <td>(sex_0)</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.119910</td>\n",
       "      <td>0.623529</td>\n",
       "      <td>1.172766</td>\n",
       "      <td>0.017664</td>\n",
       "      <td>1.243990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(age_1)</td>\n",
       "      <td>(sex_0)</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.128959</td>\n",
       "      <td>0.626374</td>\n",
       "      <td>1.178116</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>1.253460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(age_2)</td>\n",
       "      <td>(sex_0)</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.104072</td>\n",
       "      <td>0.567901</td>\n",
       "      <td>1.068138</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>1.083840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(bmi_0)</td>\n",
       "      <td>(sex_0)</td>\n",
       "      <td>0.201357</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.149321</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>1.394788</td>\n",
       "      <td>0.042265</td>\n",
       "      <td>1.812217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(bmi_3)</td>\n",
       "      <td>(sex_0)</td>\n",
       "      <td>0.196833</td>\n",
       "      <td>0.531674</td>\n",
       "      <td>0.106335</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>1.016092</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>1.018609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285849</th>\n",
       "      <td>(bp_1, s4_0, s3_1, s6_1)</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, bmi_0, s2_0)</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>44.200000</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>1.977376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285850</th>\n",
       "      <td>(bp_1, s2_0, s3_1, s6_1)</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s4_0, bmi_0)</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>82.875000</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>3.963801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285851</th>\n",
       "      <td>(bp_1, bmi_0, s3_1, s6_1)</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s4_0, s2_0)</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>3.945701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285852</th>\n",
       "      <td>(bmi_0, s2_0, s3_1, s6_1)</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s4_0, bp_1)</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>36.833333</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>1.972851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285853</th>\n",
       "      <td>(bp_1, s2_0, s3_1, bmi_0)</td>\n",
       "      <td>(s5_0, s1_0, target_0, sex_1, s4_0, s6_1)</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>55.250000</td>\n",
       "      <td>0.006664</td>\n",
       "      <td>1.981900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285854 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      antecedents                                 consequents  \\\n",
       "0                         (age_0)                                     (sex_0)   \n",
       "1                         (age_1)                                     (sex_0)   \n",
       "2                         (age_2)                                     (sex_0)   \n",
       "3                         (bmi_0)                                     (sex_0)   \n",
       "4                         (bmi_3)                                     (sex_0)   \n",
       "...                           ...                                         ...   \n",
       "285849   (bp_1, s4_0, s3_1, s6_1)  (s5_0, s1_0, target_0, sex_1, bmi_0, s2_0)   \n",
       "285850   (bp_1, s2_0, s3_1, s6_1)  (s5_0, s1_0, target_0, sex_1, s4_0, bmi_0)   \n",
       "285851  (bp_1, bmi_0, s3_1, s6_1)   (s5_0, s1_0, target_0, sex_1, s4_0, s2_0)   \n",
       "285852  (bmi_0, s2_0, s3_1, s6_1)   (s5_0, s1_0, target_0, sex_1, s4_0, bp_1)   \n",
       "285853  (bp_1, s2_0, s3_1, bmi_0)   (s5_0, s1_0, target_0, sex_1, s4_0, s6_1)   \n",
       "\n",
       "        antecedent support  consequent support   support  confidence  \\\n",
       "0                 0.192308            0.531674  0.119910    0.623529   \n",
       "1                 0.205882            0.531674  0.128959    0.626374   \n",
       "2                 0.183258            0.531674  0.104072    0.567901   \n",
       "3                 0.201357            0.531674  0.149321    0.741573   \n",
       "4                 0.196833            0.531674  0.106335    0.540230   \n",
       "...                    ...                 ...       ...         ...   \n",
       "285849            0.013575            0.011312  0.006787    0.500000   \n",
       "285850            0.009050            0.009050  0.006787    0.750000   \n",
       "285851            0.009050            0.013575  0.006787    0.750000   \n",
       "285852            0.013575            0.013575  0.006787    0.500000   \n",
       "285853            0.013575            0.009050  0.006787    0.500000   \n",
       "\n",
       "             lift  leverage  conviction  \n",
       "0        1.172766  0.017664    1.243990  \n",
       "1        1.178116  0.019497    1.253460  \n",
       "2        1.068138  0.006639    1.083840  \n",
       "3        1.394788  0.042265    1.812217  \n",
       "4        1.016092  0.001684    1.018609  \n",
       "...           ...       ...         ...  \n",
       "285849  44.200000  0.006634    1.977376  \n",
       "285850  82.875000  0.006705    3.963801  \n",
       "285851  55.250000  0.006664    3.945701  \n",
       "285852  36.833333  0.006603    1.972851  \n",
       "285853  55.250000  0.006664    1.981900  \n",
       "\n",
       "[285854 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "display(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using rules for feature selection\n",
    "\n",
    "As you see above, there can be quite a few rules generated.  It is not practical to look at over 280,000 rules looking for something useful to stand out.  So how can we use all that information to help make predictions?  First, by understanding the format of a rule as `{A1..An} -> {C1..Cn}` or more succintly `A -> C`, we can make the observation that the antecedents are predicting the prescence of the consequent, with some measure of \"interestingness\" like confidence or conviction.  If we are interested in predicting the `target` as the dependent variable, then we really are interested in finding rules where target is the only item in the consequent.\n",
    "\n",
    "We can use a masking technique similar to one we used in lab 1 to find such rules.  We will use the rules given by the conviction metric threshold.  Conviction has the advantge over confidence in that it accounts for the direction of the rule, i.e. conviction(A -> C) ≠ conviction(C -> A).  This is useful to us because we only care about the antecedent relationship to the presence of the consequent (target in our case), and not the other way around.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>(bmi_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.201357</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.126697</td>\n",
       "      <td>0.629213</td>\n",
       "      <td>1.918016</td>\n",
       "      <td>0.060641</td>\n",
       "      <td>1.812217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>(bp_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.131222</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>1.681807</td>\n",
       "      <td>0.029350</td>\n",
       "      <td>1.498956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>(s3_3)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>1.688276</td>\n",
       "      <td>0.033205</td>\n",
       "      <td>1.506085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>(s3_4)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.022624</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>2.344828</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>2.911765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>(s4_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.382353</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.203620</td>\n",
       "      <td>0.532544</td>\n",
       "      <td>1.623342</td>\n",
       "      <td>0.078187</td>\n",
       "      <td>1.437453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283972</th>\n",
       "      <td>(s5_0, s1_0, sex_1, s3_1, s4_0, s6_1, bp_1, s2_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.048276</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284214</th>\n",
       "      <td>(s5_0, s1_0, bmi_0, s3_1, s4_0, age_0, bp_1, s...</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.048276</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284426</th>\n",
       "      <td>(s5_0, s1_0, bmi_0, s3_1, s4_0, s6_1, bp_1, s2_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.048276</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284648</th>\n",
       "      <td>(s5_0, s1_0, sex_1, s3_1, bmi_0, s4_0, age_0, ...</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.048276</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285252</th>\n",
       "      <td>(s5_0, s1_0, sex_1, s3_1, bmi_0, s4_0, s6_1, b...</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.048276</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10642 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              antecedents consequents  \\\n",
       "57                                                (bmi_0)  (target_0)   \n",
       "63                                                 (bp_0)  (target_0)   \n",
       "88                                                 (s3_3)  (target_0)   \n",
       "92                                                 (s3_4)  (target_0)   \n",
       "97                                                 (s4_0)  (target_0)   \n",
       "...                                                   ...         ...   \n",
       "283972  (s5_0, s1_0, sex_1, s3_1, s4_0, s6_1, bp_1, s2_0)  (target_0)   \n",
       "284214  (s5_0, s1_0, bmi_0, s3_1, s4_0, age_0, bp_1, s...  (target_0)   \n",
       "284426  (s5_0, s1_0, bmi_0, s3_1, s4_0, s6_1, bp_1, s2_0)  (target_0)   \n",
       "284648  (s5_0, s1_0, sex_1, s3_1, bmi_0, s4_0, age_0, ...  (target_0)   \n",
       "285252  (s5_0, s1_0, sex_1, s3_1, bmi_0, s4_0, s6_1, b...  (target_0)   \n",
       "\n",
       "        antecedent support  consequent support   support  confidence  \\\n",
       "57                0.201357            0.328054  0.126697    0.629213   \n",
       "63                0.131222            0.328054  0.072398    0.551724   \n",
       "88                0.147059            0.328054  0.081448    0.553846   \n",
       "92                0.029412            0.328054  0.022624    0.769231   \n",
       "97                0.382353            0.328054  0.203620    0.532544   \n",
       "...                    ...                 ...       ...         ...   \n",
       "283972            0.006787            0.328054  0.006787    1.000000   \n",
       "284214            0.006787            0.328054  0.006787    1.000000   \n",
       "284426            0.006787            0.328054  0.006787    1.000000   \n",
       "284648            0.006787            0.328054  0.006787    1.000000   \n",
       "285252            0.006787            0.328054  0.006787    1.000000   \n",
       "\n",
       "            lift  leverage  conviction  \n",
       "57      1.918016  0.060641    1.812217  \n",
       "63      1.681807  0.029350    1.498956  \n",
       "88      1.688276  0.033205    1.506085  \n",
       "92      2.344828  0.012976    2.911765  \n",
       "97      1.623342  0.078187    1.437453  \n",
       "...          ...       ...         ...  \n",
       "283972  3.048276  0.004561         inf  \n",
       "284214  3.048276  0.004561         inf  \n",
       "284426  3.048276  0.004561         inf  \n",
       "284648  3.048276  0.004561         inf  \n",
       "285252  3.048276  0.004561         inf  \n",
       "\n",
       "[10642 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names = [x for x in data.columns if 'target' in x]\n",
    "mask = [True if c.intersection(target_names) and len(c) == 1 else False for c in rules.consequents.values]\n",
    "target_rules = rules[mask]\n",
    "display(target_rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of rules where target is the only consequent.  Lets get a list of the distinct features in the antecedent.  This will be a list of features that target is potentially dependent on, and can be used for feature selection purposes.\n",
    "\n",
    "We can't just use the unique method on the `antecedents` column because we don't want the unique sets, we want the unique items across all sets.  We will use the `*` operator in python for this. `*` will take an array-like object (such as a pandas series), and turn each element into a paramter to the function being called.  In this case, we will be passing every antecedent as a set to the union method of `frozenset`, which will union them into one set containing all the unique features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'age_0',\n",
       "           'age_1',\n",
       "           'age_2',\n",
       "           'age_3',\n",
       "           'age_4',\n",
       "           'bmi_0',\n",
       "           'bmi_1',\n",
       "           'bmi_2',\n",
       "           'bmi_3',\n",
       "           'bmi_4',\n",
       "           'bp_0',\n",
       "           'bp_1',\n",
       "           'bp_2',\n",
       "           'bp_3',\n",
       "           'bp_4',\n",
       "           's1_0',\n",
       "           's1_1',\n",
       "           's1_2',\n",
       "           's1_3',\n",
       "           's1_4',\n",
       "           's2_0',\n",
       "           's2_1',\n",
       "           's2_2',\n",
       "           's2_3',\n",
       "           's3_0',\n",
       "           's3_1',\n",
       "           's3_2',\n",
       "           's3_3',\n",
       "           's3_4',\n",
       "           's4_0',\n",
       "           's4_1',\n",
       "           's4_2',\n",
       "           's4_3',\n",
       "           's4_4',\n",
       "           's5_0',\n",
       "           's5_1',\n",
       "           's5_2',\n",
       "           's5_3',\n",
       "           's5_4',\n",
       "           's6_0',\n",
       "           's6_1',\n",
       "           's6_2',\n",
       "           's6_3',\n",
       "           's6_4',\n",
       "           'sex_0',\n",
       "           'sex_1'})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset.union(*target_rules['antecedents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is the entire feature set.  So, our rules currently are not providing a lot of value, and we still have more than 10,000 rules.  We filtered the original rules using a confidence greater than 0.5.  Lets turn to some other more interesting measures to filter the above list of rules further.\n",
    "\n",
    "## Finding \"interesting\" rules\n",
    "Rules that we are interested in include those that have some metric support that they are more than just random occurrences.  There are several metrics that can identify these rules for us.  First, we will start with lift.  Lift is kind of like correlation.  With lift, we want to see values far from 1.  Values above 1 imply a positive correlation, and below 1 indicate negative.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8485</th>\n",
       "      <td>(s4_2, sex_0, s1_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27985</th>\n",
       "      <td>(bp_2, s5_4, bmi_4)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32271</th>\n",
       "      <td>(bp_4, s6_4, s1_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32358</th>\n",
       "      <td>(bp_4, s4_2, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42619</th>\n",
       "      <td>(s5_3, age_3, bmi_4, sex_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49215</th>\n",
       "      <td>(s5_3, bp_1, bmi_4, sex_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49878</th>\n",
       "      <td>(s5_3, bmi_4, sex_0, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.009050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.008149</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54402</th>\n",
       "      <td>(s4_2, sex_0, s1_1, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57428</th>\n",
       "      <td>(s5_3, s4_2, sex_0, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69081</th>\n",
       "      <td>(bp_2, s5_4, bmi_4, sex_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70227</th>\n",
       "      <td>(s5_2, bmi_4, sex_1, s6_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73355</th>\n",
       "      <td>(s5_3, bp_4, sex_1, s3_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87598</th>\n",
       "      <td>(s1_2, age_3, bp_3, bmi_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88058</th>\n",
       "      <td>(s5_3, age_3, bmi_4, s3_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89192</th>\n",
       "      <td>(s5_2, age_3, s2_1, s6_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89267</th>\n",
       "      <td>(s5_2, age_3, s3_1, s6_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90426</th>\n",
       "      <td>(s1_2, bmi_4, age_4, s6_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102720</th>\n",
       "      <td>(bmi_4, bp_4, s4_2, s5_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109982</th>\n",
       "      <td>(bp_4, s4_2, s6_4, s1_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112833</th>\n",
       "      <td>(s5_3, s1_2, s3_1, s6_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135098</th>\n",
       "      <td>(sex_0, bmi_4, s5_3, bp_1, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135923</th>\n",
       "      <td>(sex_0, bmi_4, s4_2, s5_3, s3_0)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143625</th>\n",
       "      <td>(sex_0, s3_1, s6_3, s5_3, s1_2)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162167</th>\n",
       "      <td>(bp_4, sex_1, s3_1, bmi_4, s5_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180020</th>\n",
       "      <td>(age_3, bp_3, s4_2, s1_2, bmi_3)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180298</th>\n",
       "      <td>(age_3, s3_1, bmi_4, s5_3, s4_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200232</th>\n",
       "      <td>(s3_1, s6_3, s5_3, s1_2, s4_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223550</th>\n",
       "      <td>(sex_0, s3_1, s6_3, s5_3, s1_2, s4_1)</td>\n",
       "      <td>(target_4)</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>0.099548</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.045455</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  antecedents consequents  antecedent support  \\\n",
       "8485                      (s4_2, sex_0, s1_1)  (target_4)            0.006787   \n",
       "27985                     (bp_2, s5_4, bmi_4)  (target_4)            0.006787   \n",
       "32271                      (bp_4, s6_4, s1_3)  (target_4)            0.006787   \n",
       "32358                      (bp_4, s4_2, s3_0)  (target_4)            0.006787   \n",
       "42619             (s5_3, age_3, bmi_4, sex_0)  (target_4)            0.006787   \n",
       "49215              (s5_3, bp_1, bmi_4, sex_0)  (target_4)            0.009050   \n",
       "49878              (s5_3, bmi_4, sex_0, s3_0)  (target_4)            0.009050   \n",
       "54402               (s4_2, sex_0, s1_1, s3_0)  (target_4)            0.006787   \n",
       "57428               (s5_3, s4_2, sex_0, s3_0)  (target_4)            0.006787   \n",
       "69081              (bp_2, s5_4, bmi_4, sex_1)  (target_4)            0.006787   \n",
       "70227              (s5_2, bmi_4, sex_1, s6_3)  (target_4)            0.006787   \n",
       "73355               (s5_3, bp_4, sex_1, s3_1)  (target_4)            0.006787   \n",
       "87598              (s1_2, age_3, bp_3, bmi_3)  (target_4)            0.006787   \n",
       "88058              (s5_3, age_3, bmi_4, s3_1)  (target_4)            0.006787   \n",
       "89192               (s5_2, age_3, s2_1, s6_3)  (target_4)            0.006787   \n",
       "89267               (s5_2, age_3, s3_1, s6_3)  (target_4)            0.006787   \n",
       "90426              (s1_2, bmi_4, age_4, s6_3)  (target_4)            0.006787   \n",
       "102720              (bmi_4, bp_4, s4_2, s5_3)  (target_4)            0.006787   \n",
       "109982               (bp_4, s4_2, s6_4, s1_3)  (target_4)            0.006787   \n",
       "112833               (s5_3, s1_2, s3_1, s6_3)  (target_4)            0.006787   \n",
       "135098       (sex_0, bmi_4, s5_3, bp_1, s3_0)  (target_4)            0.006787   \n",
       "135923       (sex_0, bmi_4, s4_2, s5_3, s3_0)  (target_4)            0.006787   \n",
       "143625        (sex_0, s3_1, s6_3, s5_3, s1_2)  (target_4)            0.006787   \n",
       "162167       (bp_4, sex_1, s3_1, bmi_4, s5_3)  (target_4)            0.006787   \n",
       "180020       (age_3, bp_3, s4_2, s1_2, bmi_3)  (target_4)            0.006787   \n",
       "180298       (age_3, s3_1, bmi_4, s5_3, s4_1)  (target_4)            0.006787   \n",
       "200232         (s3_1, s6_3, s5_3, s1_2, s4_1)  (target_4)            0.006787   \n",
       "223550  (sex_0, s3_1, s6_3, s5_3, s1_2, s4_1)  (target_4)            0.006787   \n",
       "\n",
       "        consequent support   support  confidence       lift  leverage  \\\n",
       "8485              0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "27985             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "32271             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "32358             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "42619             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "49215             0.099548  0.009050         1.0  10.045455  0.008149   \n",
       "49878             0.099548  0.009050         1.0  10.045455  0.008149   \n",
       "54402             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "57428             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "69081             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "70227             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "73355             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "87598             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "88058             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "89192             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "89267             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "90426             0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "102720            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "109982            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "112833            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "135098            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "135923            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "143625            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "162167            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "180020            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "180298            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "200232            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "223550            0.099548  0.006787         1.0  10.045455  0.006112   \n",
       "\n",
       "        conviction  \n",
       "8485           inf  \n",
       "27985          inf  \n",
       "32271          inf  \n",
       "32358          inf  \n",
       "42619          inf  \n",
       "49215          inf  \n",
       "49878          inf  \n",
       "54402          inf  \n",
       "57428          inf  \n",
       "69081          inf  \n",
       "70227          inf  \n",
       "73355          inf  \n",
       "87598          inf  \n",
       "88058          inf  \n",
       "89192          inf  \n",
       "89267          inf  \n",
       "90426          inf  \n",
       "102720         inf  \n",
       "109982         inf  \n",
       "112833         inf  \n",
       "135098         inf  \n",
       "135923         inf  \n",
       "143625         inf  \n",
       "162167         inf  \n",
       "180020         inf  \n",
       "180298         inf  \n",
       "200232         inf  \n",
       "223550         inf  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rules1 = target_rules[target_rules['lift'] > 10]\n",
    "display(rules1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we see that there are some rules with very high lift, and the conviction for these is also infinite.  This may seem exciting, but if you look at the support for the rule, it is very small, indicating that these rules appear in just 0.7% of the itemsets.  So these rules are very interesting but only for a very small set of the data.  If the dataset is small this may represent just a few rows of the original dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take another approach by also considering the support along with lift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>(s5_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.151584</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>2.047349</td>\n",
       "      <td>0.052082</td>\n",
       "      <td>2.046380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>(s5_0, bmi_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>2.201533</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>2.419005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>(bmi_0, s6_1)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2.190948</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>2.389140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>(s4_0, bp_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2.190948</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>2.389140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>(s4_0, s5_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.128959</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>2.139141</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>2.252994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9849</th>\n",
       "      <td>(s4_0, s5_0, sex_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.092760</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.061086</td>\n",
       "      <td>0.658537</td>\n",
       "      <td>2.007401</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>1.967841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24652</th>\n",
       "      <td>(s4_0, s5_0, bmi_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>2.151724</td>\n",
       "      <td>0.029064</td>\n",
       "      <td>2.284615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               antecedents consequents  antecedent support  \\\n",
       "105                 (s5_0)  (target_0)            0.151584   \n",
       "2021         (s5_0, bmi_0)  (target_0)            0.081448   \n",
       "2029         (bmi_0, s6_1)  (target_0)            0.072398   \n",
       "2525          (s4_0, bp_0)  (target_0)            0.072398   \n",
       "3724          (s4_0, s5_0)  (target_0)            0.128959   \n",
       "9849   (s4_0, s5_0, sex_0)  (target_0)            0.092760   \n",
       "24652  (s4_0, s5_0, bmi_0)  (target_0)            0.076923   \n",
       "\n",
       "       consequent support   support  confidence      lift  leverage  \\\n",
       "105              0.328054  0.101810    0.671642  2.047349  0.052082   \n",
       "2021             0.328054  0.058824    0.722222  2.201533  0.032104   \n",
       "2029             0.328054  0.052036    0.718750  2.190948  0.028286   \n",
       "2525             0.328054  0.052036    0.718750  2.190948  0.028286   \n",
       "3724             0.328054  0.090498    0.701754  2.139141  0.048192   \n",
       "9849             0.328054  0.061086    0.658537  2.007401  0.030656   \n",
       "24652            0.328054  0.054299    0.705882  2.151724  0.029064   \n",
       "\n",
       "       conviction  \n",
       "105      2.046380  \n",
       "2021     2.419005  \n",
       "2029     2.389140  \n",
       "2525     2.389140  \n",
       "3724     2.252994  \n",
       "9849     1.967841  \n",
       "24652    2.284615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rules2 = target_rules[(target_rules['lift'] > 2) & (target_rules['support'] > 0.05)] \n",
    "display(rules2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a smaller set of rules that appear in at least 5% of our data, and also have a lift that indicates some dependency between the antecedent and consequent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conviction\n",
    "\n",
    "Conviction has the distinct advantage over other metrics in that it's score is dependent on the direction of the rule.  The antecedent and consequent are taken into account when computing conviction, and this is useful when we want interesting rules whose consequent is the target feature we care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>(s5_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.151584</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.101810</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>2.047349</td>\n",
       "      <td>0.052082</td>\n",
       "      <td>2.046380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>(s5_0, bmi_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.081448</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>2.201533</td>\n",
       "      <td>0.032104</td>\n",
       "      <td>2.419005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>(bmi_0, s6_1)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2.190948</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>2.389140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>(s4_0, bp_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.072398</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>2.190948</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>2.389140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>(s4_0, s5_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.128959</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>0.701754</td>\n",
       "      <td>2.139141</td>\n",
       "      <td>0.048192</td>\n",
       "      <td>2.252994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24652</th>\n",
       "      <td>(s4_0, s5_0, bmi_0)</td>\n",
       "      <td>(target_0)</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.328054</td>\n",
       "      <td>0.054299</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>2.151724</td>\n",
       "      <td>0.029064</td>\n",
       "      <td>2.284615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               antecedents consequents  antecedent support  \\\n",
       "105                 (s5_0)  (target_0)            0.151584   \n",
       "2021         (s5_0, bmi_0)  (target_0)            0.081448   \n",
       "2029         (bmi_0, s6_1)  (target_0)            0.072398   \n",
       "2525          (s4_0, bp_0)  (target_0)            0.072398   \n",
       "3724          (s4_0, s5_0)  (target_0)            0.128959   \n",
       "24652  (s4_0, s5_0, bmi_0)  (target_0)            0.076923   \n",
       "\n",
       "       consequent support   support  confidence      lift  leverage  \\\n",
       "105              0.328054  0.101810    0.671642  2.047349  0.052082   \n",
       "2021             0.328054  0.058824    0.722222  2.201533  0.032104   \n",
       "2029             0.328054  0.052036    0.718750  2.190948  0.028286   \n",
       "2525             0.328054  0.052036    0.718750  2.190948  0.028286   \n",
       "3724             0.328054  0.090498    0.701754  2.139141  0.048192   \n",
       "24652            0.328054  0.054299    0.705882  2.151724  0.029064   \n",
       "\n",
       "       conviction  \n",
       "105      2.046380  \n",
       "2021     2.419005  \n",
       "2029     2.389140  \n",
       "2525     2.389140  \n",
       "3724     2.252994  \n",
       "24652    2.284615  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rules3 = target_rules[(target_rules['conviction'] > 2) & (target_rules['support'] > 0.05)] \n",
    "display(rules3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we got nearly the same set of rules as we did using lift, with just one exception.  We eliminated the `(sex_0, s4_0, s5_0) -> (target_0)` rule because its conviction was just below 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection: get the unique antecedents in these rules\n",
    "A primary use case of ARM is to mine for features that are associated with a target.  If you have a large dataset and/or a lot of features, this method can help to narrow down which features might prove the most useful to include in statistical modeling.  \n",
    "\n",
    "The code below will give us a list of features that we could investigate further with other methods like regression or decision trees, for example.  There is less utility in this approach if you are planning to use a machine learning method that is robust to large feature sets like random forest, XGBoost, or neural networks, but those methods are plagued by a lack of transparency in how the predictions are made.  We've already discussed the issue of non-transparent models in the health care space previously in this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'bmi_0', 'bp_0', 's4_0', 's5_0', 's6_1'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frozenset.union(*rules3['antecedents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results indicate that bmi, bp, s4, s5, and s6 may be strong predictors of the target.  You can experiment with using different metrics and thresholds to see the effect on this final set of features.  The identified features can be run through other machine learning models such as regression as selected features, or you can simply use the rules themselves to make a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using rules for prediction\n",
    "\n",
    "While the primary usecase of ARM is not to create a predictive model, using the generated rules for prediction is straightforward.  Pick a rule, such as this rule `(s4_0, s5_0, bmi_0) -> (target_0)`.  When you see data such that a patient has bmi class 0, s4 class 0, and s5 class 0, you can predict target class 0 with a confidence of about 70.5%.\n",
    "\n",
    "You will note that from the target table, the support for the rule is only about 5.4%, meaning this rule covers 5.4% of the frequent itemsets.  The confidence of the rule is 70.5%, meaning that 70.5% of the time the frequent itemsets contains bmi class 0, s4 class 0, and s5 class 0, it also contains target class 0.  This can be interpreted as a measure of accuracy.  There may be other rules that are associated with different classes, but with much lower support or confidence.  \n",
    "\n",
    "You have to be careful with this approach becasue it is easy to overfit the data for predictions, and in fact we've used the entire dataset to generate these rules, so the full set of rules is actually fitted fairly completely to the original data.\n",
    "\n",
    "Some practical considerations of using rules for classification generally preclude this approach.  One consideration is that the new data you wish to classify must be itemized in the same way as the training data set.  If you have used KMeans to bin data as we have, then you must save that transformation and reuse it, otherwise the bins could shift with the addition of new data.  This leads to the second problem, which isn't unique to ARM but more obvious.  New data may be outside the original ranges used for itemization, and therefore unable to be fit into the existing association rules.\n",
    "\n",
    "In short, for this data set, with our current metric threshold, we have covered very little in the way of predicting diabetes disease progression accurately using just association rules.  When this is the case, it may be better to focus on the feature selection method and proceed with other machine learning methods that can handle continuous valued variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
