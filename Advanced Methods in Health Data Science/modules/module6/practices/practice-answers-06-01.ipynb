{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 Practice 1 Answers - Grid searching the best Random Forest classifier\n",
    "\n",
    "In the labs we saw that the random forest performed the best using mostly deafult parameters for the model.  In this practice, you will use a grid search to see if the model can be improved with different model hyper parameters.  We will continue to use the same dataset to predict 30 day hospital readmission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformations to our data\n",
    "These are the same transformations as applied in the labs.  See Lab 1 for more explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('../resources/diabetes_readmission.csv')\n",
    "display(data.head())\n",
    "\n",
    "y = data['readmitted']\n",
    "X = data[['discharge', 'age', 'race', 'admission_type', 'specialty', 'time_in_hospital', 'diag_1', 'A1Cresult', 'change']].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X['time_in_hospital'] = scaler.fit_transform(X[['time_in_hospital']])\n",
    "\n",
    "# create dummy variables\n",
    "X = pd.concat([X, pd.get_dummies(X['age'], prefix = 'age', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['race'], prefix = 'race', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['admission_type'], prefix = 'admission_type', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['specialty'], prefix = 'specialty', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['diag_1'], prefix = 'diag_1', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['A1Cresult'], prefix = 'A1Cresult', drop_first=True)], axis=1)\n",
    "\n",
    "# drop originals\n",
    "X = X.drop(['age', 'race', 'admission_type', 'specialty', 'diag_1', 'A1Cresult'], axis=1)\n",
    "\n",
    "# balance the classes\n",
    "display(y.value_counts())\n",
    "\n",
    "X_oversampled, y_oversampled = resample(X[y == 1], y[y == 1], replace=True, n_samples=X[y == 0].shape[0], random_state=42)\n",
    "\n",
    "X = pd.DataFrame(np.vstack((X[y == 0], X_oversampled)), columns=X.columns)\n",
    "y = np.hstack((y[y == 0], y_oversampled))\n",
    "\n",
    "display(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a grid search using cross validation\n",
    "Perform a grid search of the following parameters:\n",
    "\n",
    "* n_estimators - the number of trees to generate\n",
    "* criterion - the method for determing the quality of a split in the tree\n",
    "* max_depth - the mximum number of splits in the tree\n",
    "\n",
    "Refer to the [documentation for RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for the valid values for these parameters.  You may select any set of values that you feel are appropriate.\n",
    "\n",
    "Initialize the model with a random_state for reproducible results.\n",
    "\n",
    "For scoring the grid search, we will use both accuracy and AUC for selecting the best set of parameters.  The values to specify for these can be found [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter).  Refer to the documentation for [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [this example](https://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py) to see how to specify multiple metrics.  Use the AUC as the final metric for refitting.\n",
    "\n",
    "Depending on the number of parameter options you specify in the grid search, this process could take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 200, 500],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [10, 30, None],\n",
    "}\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring={'acc': 'accuracy','auc': 'roc_auc'}, refit='auc')\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best model: %f with parameters %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the best model from the grid search\n",
    "Get the best model, print the accuracy, and visualize the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = grid.best_estimator_\n",
    "\n",
    "print('accuracy', model.score(X, y))\n",
    "\n",
    "probs = model.predict_proba(X)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
