{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6 Lab 6 - Grid searching for the best model hyper parameters\n",
    "\n",
    "A grid search is an automated way to fit a model with different hyper parameters and compare the results in order to find the best performing model.  Hyper parameters are those parameters that control how the model is defined, fitted and trainied, but are not related to the training data itself.  In this lab, we will see how to do a grid search on a decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformations to our data\n",
    "These are the same transfomrations as applied in the labs.  See Lab 1 for more explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmitted</th>\n",
       "      <th>discharge</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>specialty</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>diag_1</th>\n",
       "      <th>A1Cresult</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   readmitted  discharge  age  race  admission_type  specialty  \\\n",
       "0           1          0    0     1               1          0   \n",
       "1           0          0    0     1               1          4   \n",
       "2           0          1    2     1               1          2   \n",
       "3           0          0    2     1               1          2   \n",
       "4           0          0    0     0               1          2   \n",
       "\n",
       "   time_in_hospital  diag_1  A1Cresult  change  \n",
       "0                 8       8          0       1  \n",
       "1                 2       8          0       0  \n",
       "2                 4       8          2       0  \n",
       "3                 3       8          3       1  \n",
       "4                 5       8          0       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    60145\n",
       "1     5813\n",
       "Name: readmitted, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    60145\n",
       "0    60145\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('../resources/diabetes_readmission.csv')\n",
    "display(data.head())\n",
    "\n",
    "y = data['readmitted']\n",
    "X = data[['discharge', 'age', 'race', 'admission_type', 'specialty', 'time_in_hospital', 'diag_1', 'A1Cresult', 'change']].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X['time_in_hospital'] = scaler.fit_transform(X[['time_in_hospital']])\n",
    "\n",
    "# create dummy variables\n",
    "X = pd.concat([X, pd.get_dummies(X['age'], prefix = 'age', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['race'], prefix = 'race', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['admission_type'], prefix = 'admission_type', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['specialty'], prefix = 'specialty', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['diag_1'], prefix = 'diag_1', drop_first=True)], axis=1)\n",
    "X = pd.concat([X, pd.get_dummies(X['A1Cresult'], prefix = 'A1Cresult', drop_first=True)], axis=1)\n",
    "\n",
    "# drop originals\n",
    "X = X.drop(['age', 'race', 'admission_type', 'specialty', 'diag_1', 'A1Cresult'], axis=1)\n",
    "\n",
    "# balance the classes\n",
    "display(y.value_counts())\n",
    "\n",
    "X_oversampled, y_oversampled = resample(X[y == 1], y[y == 1], replace=True, n_samples=X[y == 0].shape[0], random_state=42)\n",
    "\n",
    "X = pd.DataFrame(np.vstack((X[y == 0], X_oversampled)), columns=X.columns)\n",
    "y = np.hstack((y[y == 0], y_oversampled))\n",
    "\n",
    "display(pd.Series(y).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search and cross validation\n",
    "For grid searching, we will not be using a train/test split, and instead use cross validation, as that method is directly supported by scikit learn's [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class.\n",
    "\n",
    "The first task we must do is to select the hyper parameters we wish to grid search.  We can tune any parameter that is involved in the building of the model, which includes any of the parameters for the class constructor as well as any custom functions we may have developed for returning a model (as is the case for building a model using KerasClassifier)\n",
    "\n",
    "The [documentation for DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) will give us some idea of what we can tune.\n",
    "\n",
    "In this practice you will grid search the following parameters:\n",
    "\n",
    "* criterion - the method for determing the quality of a split in the tree\n",
    "* splitter - how to choose the best split\n",
    "* max_depth - the mximum number of splits in the tree\n",
    "\n",
    "Refer to the documentation for the valid values for these parameters.\n",
    "\n",
    "For scoring the grid search, we will use accuracy for selecting the best set of parameters.  The values to specify for these can be found [here](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: 0.648408 with parameters {'criterion': 'entropy', 'max_depth': None, 'splitter': 'random'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [1, 5, 10, 20, None],\n",
    "    'splitter': ['best', 'random'],\n",
    "}\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='accuracy')\n",
    "grid_result = grid.fit(X, y)\n",
    "\n",
    "print(\"Best model: %f with parameters %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The best model was identified as having been fit with `{'criterion': 'entropy', 'max_depth': None, 'splitter': 'random'}`, and an accuracy of ~0.64.  (Note that we cannot compare this to lab 2 accuracy because that was assessed on a test data set versus cross validation).\n",
    "\n",
    "You will note that the values for criterion and splitter differ from the defaults for DecisionTreeClassifier, which supports the idea that searching for the best hyper parameters for a model is a worthwhile effort.\n",
    "\n",
    "## Retrieving the best estimator and saving the model\n",
    "\n",
    "We can save the model to a file for later use, such as if we want to reload it and apply it to a new data set.  We can also directly get the best estimator for immediate use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# get the best estimator to use immediately if we want\n",
    "best = grid.best_estimator_\n",
    "\n",
    "# save to a file\n",
    "joblib.dump(best, '../../../output/best_rf_model.pkl')\n",
    "\n",
    "# load from a file\n",
    "best = joblib.load('../../../output/best_rf_model.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results of the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6827167678111231\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:\n",
      "[[39815 20330]\n",
      " [17836 42309]]\n",
      "\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68     60145\n",
      "           1       0.68      0.70      0.69     60145\n",
      "\n",
      "    accuracy                           0.68    120290\n",
      "   macro avg       0.68      0.68      0.68    120290\n",
      "weighted avg       0.68      0.68      0.68    120290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = best\n",
    "print('accuracy', model.score(X, y))\n",
    "\n",
    "probs = model.predict_proba(X)\n",
    "preds = probs[:,1]\n",
    "\n",
    "fpr, tpr, threshold = metrics.roc_curve(y, preds)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "cmatrix = confusion_matrix(y, y_pred)\n",
    "print('confusion matrix:')\n",
    "print(cmatrix)\n",
    "print('\\nclassification report:')\n",
    "print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
