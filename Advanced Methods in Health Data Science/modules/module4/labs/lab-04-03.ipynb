{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Lab 3 - Convolutional Neural Network for image classification\n",
    "\n",
    "## **NOTE: You need to use the Tensorflow CPU container for this notebook**\n",
    "(It may take a while for this container to start and for your notebook to connect to a kernel, so be patient)\n",
    "\n",
    "In this lab we will train a Convolutional Neural Network (CNN) to classify images as positive or negative for brain tumor.\n",
    "\n",
    "We are installing and using Keras version 2.3.1 which is compatible with Tensforflow 1.x.  Keras is an abstraction layer on top of the tensorflow backend that presents higher level layers to work with, rather than building out a tensor flow manually.\n",
    "\n",
    "Please watch the video from JAMA to refresh your memory on how a CNN works, linked from this module's Schedule.ipynb.\n",
    "\n",
    "An in-depth course on neural networks, including CNN's, would take more time than we have in this course, so don't worry too much if you don't fully grasp the fundamentals of the CNN we build below.  Having exposure to it and being able to make simple changes to the network design is all that is required for this course.\n",
    "\n",
    "The labeled image data was provided by the [Mayo Radiology Informatics Laboratory](https://www.mayo.edu/research/labs/radiology-informatics/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras==2.3.1 in /opt/conda/lib/python3.7/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.7)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.2.1)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.1.2)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (2.9.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.21.5)\n",
      "Requirement already up-to-date: numpy>=1.2 in /opt/conda/lib/python3.7/site-packages (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras==2.3.1\n",
    "!{sys.executable} -m pip install --upgrade \"numpy>=1.2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "We will build a sequential model, which means each layer output goes into only one following layer's input.  There are no parallel layers in a sequential model.  \n",
    "\n",
    "For each layer except the last, we use the rectified linear activation function (relu), and for the last layer we use the sigmoid.  Sigmoid (otherwise known as the logistic function) is appropriate to output for a binary classification problem such as this one (tumor or no tumor), just as it is used in other binary classification problems such as logistic regression.\n",
    "\n",
    "The `Conv2D` layers are the layers that take small windows (kernel_size) out of each image and output filters for the next layer.\n",
    "In a CNN, at each successive convolution, it is common to increase the filters, and also common to use powers of 2.\n",
    "\n",
    "A `MaxPooling2D` layer will take the maximum value for each area defined by `pool_size`.  \n",
    "\n",
    "The `BatchNormalization` layer normalizes the outputs such they have a mean near zero and a standard deviation near 1.\n",
    "\n",
    "A `Dropout` layer will randomly set inputs to zero, to help with prevention of overfitting, at the rate specified. A value of 0.5 will set approximately half of the  inputs to zero.\n",
    "\n",
    "In the first convolution layer, we specify the dimensions and color depth of our images with the parameter `input_shape`.  Near the end, we apply some `Dense` layers, which are fully connected neural network layers, in which we specify the number of outputs we want.  We eventually want to scale the output to 1, because we are classifying a binary problem: tumor or no tumor.  The last layer is then the Sigmoid activation, which converts the output of the CNN to a probability.  The Sigmoid function is the familiar \"S\" shaped function map that is commonly used in binary classifications.\n",
    "\n",
    "Finally, as we compile the model, we specify a loss function.  The loss function is responsible for estimating the error of the network so that prior to the next training iteration, the network weights can be updated to attempt to minimize this loss.  For a binary classification problem, the `binary_crossentropy` function is used.  We also specify the optimizer algorithm, which is responsible for propogating changes to the network's weights back through the model.  We will use the Adaptive Moment Estimation (adam), as it is the newest and most efficient algorithm available.\n",
    "\n",
    "This particular network was produced by the Mayo Radiology Informatics Laboratory, from which our data was sourced, but it doesn't necessarily represent the best possible model.  When training a CNN, many of the items specified at each layer can be tuned, along with the number and order of the layers.  For this lab, we will see how this model performs.  In the practice exercise, you will modify some parameters to see the effects.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_channels, img_rows, img_cols):\n",
    "    # img_channels: how many color channels\n",
    "    # img_rows and img_cols: the size of the image\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size = 3, padding='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size = 5, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 5, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, kernel_initializer=\"he_normal\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(32, kernel_initializer=\"he_normal\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # learning rate optimizer\n",
    "    optimizer = Adadelta(lr=0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "img_rows=32\n",
    "img_cols=32\n",
    "img_channels=1\n",
    "\n",
    "model = create_model(img_channels, img_rows, img_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the training data\n",
    "\n",
    "The data are separated into two directories, one for postive samples (a tumor exists), and one for negative.  In each directory there are a number of jpeg files of 32x32 pixels.  These images are small to speed up the training process and reduce the memory necessary to train, at the expense of information loss.  \n",
    "\n",
    "We will load these images into numpy arrays, one for each of the classes, then join them together.  We will also create a binary classification array for the network to train against.\n",
    "\n",
    "We perform a train/test split so we have some images to test the model against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data(filename):\n",
    "    # read grayscale image data to an 2d numpy array\n",
    "    image = Image.open(filename)\n",
    "    image = image.getdata()\n",
    "    image = np.array(image)\n",
    "    return image.reshape(-1)\n",
    "\n",
    "\n",
    "def image_dir_to_array(dir):\n",
    "    data = [read_image_data(image) for image in glob.glob(os.path.join(dir, '*.jpg'))]\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def load_data(negative_images_path, positive_images_path):\n",
    "    negatives = image_dir_to_array(negative_images_path)\n",
    "    positives = image_dir_to_array(positive_images_path)\n",
    "    \n",
    "    X=np.vstack((negatives, positives))\n",
    "    X=X.astype(np.float) / 255 # reduce colordepth normalize the image grayscale values from 0..1\n",
    "    y=np.concatenate((np.zeros(len(negatives)), np.ones(len(positives))))\n",
    "    \n",
    "    print ('shape of X', np.shape(X)) \n",
    "    print ('scale of X', np.min(X), np.max(X))\n",
    "    print ('shape of y', np.shape(y)) \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def reshape_X(X, img_channels, img_rows, img_cols):\n",
    "    # reshape the data to the 4 dimensional format required by the CNN\n",
    "    # the resulting shape will be (num_samples, img_channels (1 for grayscale images), img_rows, img_cols)\n",
    "    return X.reshape(-1, img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (8710, 1024)\n",
      "scale of X 0.0 1.0\n",
      "shape of y (8710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "negative_images_path = '../resources/cnn-images/negative_images/'\n",
    "positive_images_path = '../resources/cnn-images/positive_images/'\n",
    "\n",
    "X, y = load_data(negative_images_path, positive_images_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = reshape_X(X_train, img_channels, img_rows, img_cols)\n",
    "X_test = reshape_X(X_test, img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Now we will train the model using the training data.  We specify a batch size and an epoch.  The batch size represents how many images we send through the network before the network weights are changed.  For a batch size of 32, the full training data is broken up into sets of 32 and sent one at a time through the network.  After each batch, the network weights are updated, and the next batch is sent through.  Larger batch sizes are more efficient, but produce worse/slower to converge models, whereas smaller batch sizes will produce better models but take more time to train.\n",
    "\n",
    "The number of epochs represent how many times the model will see one complete set of data.\n",
    "\n",
    "Both of these can be tuned and will have an effect on the model.  For this lab, we are using a small number of epochs to reduce the time it takes to train.  However, this means that the model's accuracy will be unstable.  Networks weights are randomly assigned when the model is created, so it will take a fair amount of epochs for the same model to converge to a similar set of weights with successive trainings.  Also, because of the `Dropout` layers in the model, there is a random effect to the network weights that also stabilize over time.  If you were to run this notebook multiple times in succession, you would see the ROC and other metrics change because we are using a small number of epochs (for training speed).\n",
    "\n",
    "The learning rate controls how much the network weights can change each time the weights are updated.  In this model we are using a step wise decay of the learning rate based on the epoch.  As the epoch increases, the learning rate is reduced, leading to less change in the model over time.  A static learning rate can also be used, in which case the learning rate does not change during the course of training.\n",
    "\n",
    "### The `fit` method\n",
    "\n",
    "We are specifying the learning rate function and a model checkpoint in the `callbacks` parameter of the `fit` method.  `callbacks` takes an array of classes that will be called at the end of each epoch, and we use that to update our learning rate with the `step_decay` function we defined, as well as using the built in `ModelCheckpoint` function.  The `ModelCheckpoint` will save our best model at the end of each epoch.  If the current model at the end of each epoch is not better than one produced in a prior epoch, then it is not saved.  This is a good habit because sometimes training can crash for any number of reasons (out of memory, power loss, etc), and you don't want to lose the current network state, especially if you've been training for many hours or even days.  The saved model can be used to instantiate a new model with those saved weights.\n",
    "\n",
    "The `validation_split` parameter is the percentage of data to hold out as validation to be used for checking the model at each epoch to data that was not used for training.\n",
    "\n",
    "Finally, we specify `shuffle` = True in the `fit` method, so that the training data is shuffled prior to each epoch.  This helps to ensure the model is not learning the order of the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate schedule dynamically calculated based on the epoch\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.3\n",
    "    epochs_drop = 30.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    print ('learning rate', lrate)\n",
    "    return lrate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6271 samples, validate on 697 samples\n",
      "Epoch 1/5\n",
      "learning rate 0.01\n",
      "6271/6271 [==============================] - 9s 1ms/step - loss: 1.0835 - accuracy: 0.4825 - val_loss: 0.7064 - val_accuracy: 0.2654\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70642, saving model to model.h5\n",
      "Epoch 2/5\n",
      "learning rate 0.01\n",
      "6271/6271 [==============================] - 7s 1ms/step - loss: 0.8583 - accuracy: 0.5589 - val_loss: 0.6994 - val_accuracy: 0.3286\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70642 to 0.69943, saving model to model.h5\n",
      "Epoch 3/5\n",
      "learning rate 0.01\n",
      "6271/6271 [==============================] - 6s 912us/step - loss: 0.7521 - accuracy: 0.6104 - val_loss: 0.6832 - val_accuracy: 0.6026\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.69943 to 0.68320, saving model to model.h5\n",
      "Epoch 4/5\n",
      "learning rate 0.01\n",
      "6271/6271 [==============================] - 3s 486us/step - loss: 0.7098 - accuracy: 0.6170 - val_loss: 0.6601 - val_accuracy: 0.6686\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68320 to 0.66010, saving model to model.h5\n",
      "Epoch 5/5\n",
      "learning rate 0.01\n",
      "6271/6271 [==============================] - 3s 450us/step - loss: 0.6749 - accuracy: 0.6407 - val_loss: 0.6235 - val_accuracy: 0.6815\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66010 to 0.62349, saving model to model.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f054c5fd940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size=64\n",
    "nb_epoch=5\n",
    "\n",
    "# used to save our model at the end of each epoch\n",
    "model_checkpoint = ModelCheckpoint('model.h5', verbose=1, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# create a learning rate callback\n",
    "learning_rate = LearningRateScheduler(step_decay)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_split=0.1,\n",
    "          callbacks=[model_checkpoint,learning_rate], shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see each of the five epochs output several values:\n",
    "\n",
    "* loss - the metric that the training of the model attempts to lower.  The conceptual difference between what was computed on the training set and what was expected.\n",
    "* accuracy - the accuracy of the classification on the training set\n",
    "* val_loss - same as loss, but on the validation data\n",
    "* val_accuracy - same as accuracy, but on the validation data\n",
    "\n",
    "The goal in training the network is to optimize these values.  We want to see the loss stabilize at a hopefully low level, and the accuracy also stabilize at a hopefully high level.\n",
    "\n",
    "## Test the model\n",
    "Finally, we will use the built model to test the accuracy against the test data set to get some additional metrics.  We apply the common methods used for any binary classification problem to assess the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC: 0.705\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test, batch_size = 32)\n",
    "roc = roc_auc_score(y_test, Y_pred)\n",
    "print(\"ROC:\", round(roc, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create ROC plot\n",
    "fpr, tpr, threshold = roc_curve(y_test, Y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1-score gives you the harmonic mean of precision and recall. The scores corresponding to every class will tell you the accuracy of the classifier in classifying the data points in that particular class compared to all other classes.\n",
      "The support is the number of samples of the true response that lie in that class.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative     0.4355    0.3829    0.4075       538\n",
      "    positive     0.7384    0.7782    0.7578      1204\n",
      "\n",
      "    accuracy                         0.6561      1742\n",
      "   macro avg     0.5869    0.5806    0.5827      1742\n",
      "weighted avg     0.6448    0.6561    0.6496      1742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create classification using cutoff of 0.5 probability\n",
    "Y_pred[Y_pred>=.5]=1\n",
    "Y_pred[Y_pred<.5]=0\n",
    "\n",
    "target_names=[] \n",
    "\n",
    "print(\"The f1-score gives you the harmonic mean of precision and recall. The scores corresponding to every class will tell you the accuracy of the classifier in classifying the data points in that particular class compared to all other classes.\")\n",
    "print(\"The support is the number of samples of the true response that lie in that class.\")\n",
    "target_names = ['negative', 'positive']\n",
    "\n",
    "print(classification_report(y_test, Y_pred, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching\n",
    "In practice, many of the things that we can control regarding the training of our model would be modified and run in combinations in what is called a grid search.  In a grid search, different values of parameters are specified, and the combination of those paramters are all run and evaluated.  The final model is the one in which the best metric is achieved using one of the parameter set combinations.  For example, we could do a grid search with two different batch sizes (32 and 64) and two static learning rates (0.1 and 0.075).  The model would then be fit four times:\n",
    "\n",
    "```\n",
    "batch size    learning rate\n",
    "32            0.1 \n",
    "32            0.075 \n",
    "64            0.1\n",
    "64            0.075\n",
    "    \n",
    "```\n",
    "\n",
    "We can use sklearn's [grid search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) with Keras models with a few extra steps.  We need to wrap our model creation function in a KerasClassifier class, which is compatible with sklearn.\n",
    "\n",
    "The `param_grid` dictionary specifies the parameters that we wish to pass into the grid search.  Each item in the dictionary is a parameter to either the model creation function or the fit function.  They must be specified in lists, and the combination across all of those values in each list is what makes up the grid.  The parameters that we use in our model function must remain the same because they define our image size and format, but the epochs and batch we can vary.\n",
    "\n",
    "When we call the `GridSearchCV`, the training and validation is done using Cross Validation, and we specify the number of folds in the `cv` parameter.  It's important that we pass our full dataset into this method, and not the train/test split as we have done prior.  \n",
    "\n",
    "We also specify -1 for `n_jobs`.  This parameter controls how many jobs to run in parallel.  a value of -1 tells sklearn to use as many jobs as there are CPUs.\n",
    "\n",
    "The `verbose=2` parameter will give us some output as the models are trained so we can track progress.\n",
    "\n",
    "A final note regarding the callbacks:  We are not able to pass any callbacks to the Keras fitter, so the learning rate in the below example is using the default rate for the ADAM optimizer.\n",
    "\n",
    "Running this may take a bit of time so be patient.  Also note that the grid search hides some of the verbosity we could get from running the Keras fit directly, so it may seem as though nothing is happening, but it is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Epoch 1/2\n",
      " - 5s - loss: 1.8507 - accuracy: 0.3980\n",
      "Epoch 2/2\n",
      " - 4s - loss: 1.8704 - accuracy: 0.3951\n",
      "Best model: 0.666667 with parameters {'batch_size': 64, 'epochs': 2, 'img_channels': 1, 'img_cols': 32, 'img_rows': 32}\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "\n",
    "param_grid = {\n",
    "    'img_channels': [img_channels],\n",
    "    'img_rows': [img_rows],\n",
    "    'img_cols': [img_cols],\n",
    "    'epochs': [2],\n",
    "    'batch_size': [64],\n",
    "}\n",
    "\n",
    "X = reshape_X(X, img_channels, img_rows, img_cols) # we have to reshape our input to match what the CNN expects\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv = 3, verbose=2)\n",
    "grid_result = grid.fit(X, y, shuffle=True)\n",
    "\n",
    "print(\"Best model: %f with parameters %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this lab, we built, trained, and tested a CNN that attempts to classify MRI images as having tumors or not.  The accuracy is unstable because we've used a small number of epochs.  Also, becuase the network is initialized with random weights, along with other random processes, the accuracy and ROC that you see will vary each time you run this model.  As the epochs are increased the model will become more stable, but the training will take longer.  \n",
    "\n",
    "In the practice and the exercise, you will modify some of these parameters to see their effects on the ROC and accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
