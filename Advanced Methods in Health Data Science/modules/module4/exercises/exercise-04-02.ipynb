{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4 Exercise 2 - Grid Search for the best CNN\n",
    "\n",
    "## **NOTE: You need to use the Tensorflow CPU container for this exercise**\n",
    "\n",
    "## Overview\n",
    "In this exercise, you will perform a grid search using the model defined in lab-04-03.  The model and associated code are provided.  You must write the code to load the data and do the grid search.\n",
    "\n",
    "## File Format\n",
    "\n",
    "The data are separated into two directories, one for postive samples (a tumor exists), and one for negative. In each directory there are a number of jpeg files of 32x32 pixels.  These are monochromatic images.\n",
    "\n",
    "The directories are:\n",
    "```\n",
    "negative images: ../resources/cnn-images/negative_images/*.jpg\n",
    "positive images: ../resources/cnn-images/positive_images/*.jpg\n",
    "```\n",
    "\n",
    "## Required Output\n",
    "The output required for this exercise is the grid search that you will perform.  In your grid search, you must vary three parameters for model training.  These can be the epoch, batch size, and the learning rate. \n",
    "\n",
    "hint: look at the [Keras documentation for model.compile](https://keras.io/api/models/model_training_apis/) to see how to specify a constant learning rate\n",
    "        \n",
    "## Grading\n",
    "This exercise is graded on the contents of your notebook only, as there is not a right or wrong answer to training a Convolutional Neural Network.  \n",
    "\n",
    "You will receive a score of 25 if you have performed a grid search with 3 parameters that change value (at least two values for each).  You will receive 20 points if you run a grid search using only two parameters that change value, and 15 points for using only one parameter that changes value.\n",
    "\n",
    "If your notebook doesn't run, you will receive 12 points.\n",
    "\n",
    "If you don't supply any code to do a grid search, then you will receive a score of zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.15.4)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.2.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.7)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (5.1.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from keras==2.3.1) (1.0.9)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "Collecting numpy>=1.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/46/292cff79f5b30151b027400efdb3f740ea03271b600751b6696cf550c10d/numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7MB)\n",
      "\u001b[K     |████████████████████████████████| 15.7MB 3.3MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.15.4\n",
      "    Uninstalling numpy-1.15.4:\n",
      "      Successfully uninstalled numpy-1.15.4\n",
      "Successfully installed numpy-1.21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install keras==2.3.1\n",
    "!{sys.executable} -m pip install --upgrade \"numpy>=1.2\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to build the CNN model\n",
    "\n",
    "Use the first model built in the lab as a base.  Modify it as needed to allow for grid searching with a specified learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def create_model(img_channels, img_rows, img_cols):\n",
    "    # img_channels: how many color channels\n",
    "    # img_rows and img_cols: the size of the image\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(16, kernel_size = 3, padding='same', input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size = 5, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 5, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size = 3, padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size = 2, data_format='channels_first'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, kernel_initializer=\"he_normal\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(32, kernel_initializer=\"he_normal\"))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dropout(0.5)) \n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    # learning rate optimizer\n",
    "    optimizer = Adadelta(lr=0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows=32\n",
    "img_cols=32\n",
    "img_channels=1\n",
    "\n",
    "model = create_model(img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_data(filename):\n",
    "    # read grayscale image data to an 2d numpy array\n",
    "    image = Image.open(filename)\n",
    "    image = image.getdata()\n",
    "    image = np.array(image)\n",
    "    return image.reshape(-1)\n",
    "\n",
    "\n",
    "def image_dir_to_array(dir):\n",
    "    data = [read_image_data(image) for image in glob.glob(os.path.join(dir, '*.jpg'))]\n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def load_data(negative_images_path, positive_images_path):\n",
    "    negatives = image_dir_to_array(negative_images_path)\n",
    "    positives = image_dir_to_array(positive_images_path)\n",
    "    \n",
    "    X=np.vstack((negatives, positives))\n",
    "    X=X.astype(np.float) / 255 # reduce colordepth normalize the image grayscale values from 0..1\n",
    "    y=np.concatenate((np.zeros(len(negatives)), np.ones(len(positives))))\n",
    "    \n",
    "    print ('shape of X', np.shape(X)) \n",
    "    print ('scale of X', np.min(X), np.max(X))\n",
    "    print ('shape of y', np.shape(y)) \n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def reshape_X(X, img_channels, img_rows, img_cols):\n",
    "    # reshape the data to the 4 dimensional format required by the CNN\n",
    "    # the resulting shape will be (num_samples, img_channels (1 for grayscale images), img_rows, img_cols)\n",
    "    return X.reshape(-1, img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X (8710, 1024)\n",
      "scale of X 0.0 1.0\n",
      "shape of y (8710,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "negative_images_path = '../resources/cnn-images/negative_images/'\n",
    "positive_images_path = '../resources/cnn-images/positive_images/'\n",
    "\n",
    "X, y = load_data(negative_images_path, positive_images_path)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = reshape_X(X_train, img_channels, img_rows, img_cols)\n",
    "X_test = reshape_X(X_test, img_channels, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and execute the grid search\n",
    "\n",
    "Create the parameter grid, a wrapped model, and execute the grid search.\n",
    "\n",
    "Output the best model's accuracy and it's associated parameters.\n",
    "\n",
    "Warning: Do not use excessively large number of epochs, or you will be waiting for a long time for the grid search to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Epoch 1/3\n",
      " - 5s - loss: 2.4293 - accuracy: 0.3799\n",
      "Epoch 2/3\n",
      " - 4s - loss: 2.4353 - accuracy: 0.3853\n",
      "Epoch 3/3\n",
      " - 4s - loss: 2.4673 - accuracy: 0.3788\n",
      "Best model: 1.000000 with parameters {'batch_size': 64, 'class_weight': None, 'epochs': 3, 'img_channels': 1, 'img_cols': 32, 'img_rows': 32}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "\n",
    "param_grid = {\n",
    "    'img_channels': [img_channels],\n",
    "    'img_rows': [img_rows],\n",
    "    'img_cols': [img_cols],\n",
    "    'epochs': [2, 3],\n",
    "    'batch_size': [32, 64],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "X = reshape_X(X, img_channels, img_rows, img_cols) # we have to reshape our input to match what the CNN expects\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv = 3, verbose=2)\n",
    "grid_result = grid.fit(X, y, shuffle=True)\n",
    "\n",
    "print(\"Best model: %f with parameters %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
